{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "import re\n",
    "import random\n",
    "from scipy import sparse\n",
    "from scipy.sparse import csr_matrix, vstack\n",
    "from textblob import TextBlob\n",
    "from langdetect import detect_langs\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.stem.porter import *\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from gensim.models import Word2Vec\n",
    "import multiprocessing\n",
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "from langdetect import detect\n",
    "# from wordcloud import WordCloud, STOPWORDS\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB, ComplementNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import svm\n",
    "import plotly.graph_objects as go\n",
    "# from better_profanity import profanity\n",
    "import string\n",
    "\n",
    "\n",
    "# added from here\n",
    "\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "import re\n",
    "from gensim import utils\n",
    "from gensim.models.doc2vec import LabeledSentence\n",
    "from gensim.models import Doc2Vec\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import svm\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "import nltk.collocations \n",
    "from nltk import FreqDist, word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import string, re\n",
    "import urllib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "import numpy as np\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import Ridge #import ridge \n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import neighbors \n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import RidgeClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro to Multi-Label classification\n",
    "\n",
    "Basically, there are three \"methods/ways\" to solve a multi-label classification problem:\n",
    "\n",
    "   ### 1) Problem Transformation\n",
    "   Problem Transformation: transforms our multi-label problem into single-label problem(s). This method can be carried out in three different ways as:\n",
    "     * Binary Relevance\n",
    "     * Classifier Chains\n",
    "     * Label Powerset\n",
    "   ### 2) Adapted Algorithm\n",
    "   Adapted Algorithm: adapts the algorithm to directly perform multi-label classification, rather than transforming the problem into different subsets of problems.\n",
    "     * e.g. kNN's multi-label adaptation is MLkNN. \n",
    "     \n",
    "   ### 3) Ensemble approaches\n",
    "   Ensemble Approaches: Ensemble apparently always produces better results. \n",
    "     * Scikit-Multilearn library provides different ensembling classification functions. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 1 -  Ridge Classifier \n",
    "\n",
    "### I. Problem Transformation | BinaryRelevance - RidgeClassifer()\n",
    "\n",
    " * Ridge Classifier doesn't support multi-label classification\n",
    " * Therefore, you have to implement one of the 3 multi label classification methods\n",
    " * We chose to use BinaryRelevance which is a type of \"Problem Transformation\"\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import data\n",
    "X_train = pd.read_pickle('veclyrics_doc2vec_train.pkl')\n",
    "X_test = pd.read_pickle('veclyrics_doc2vec_test.pkl')\n",
    "y_train_all = pd.read_pickle('response_doc2vec_train.pkl')\n",
    "y_test_all = pd.read_pickle('response_doc2vec_test.pkl')\n",
    "y_train_all = y_train_all.iloc[:,3:10]\n",
    "y_test_all = y_test_all.iloc[:,3:10]\n",
    "y_train_one = y_train_all.iloc[:,0]\n",
    "y_test_one = y_test_all.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_ridge = np.asarray(y_train_all)\n",
    "X_train_ridge = np.asarray(X_train)\n",
    "X_test_ridge = np.asarray(X_test)\n",
    "y_test_ridge = np.asarray(y_test_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training time taken:  5.0 seconds\n"
     ]
    }
   ],
   "source": [
    "from skmultilearn.problem_transform import BinaryRelevance\n",
    "import time\n",
    "\n",
    "start=time.time()\n",
    "classifier = BinaryRelevance(\n",
    "    classifier = RidgeClassifier(),\n",
    "    require_dense = [False, True]\n",
    ")\n",
    "\n",
    "classifier.fit(X_train_ridge, y_train_all_ridge)\n",
    "\n",
    "print('training time taken: ',round(time.time()-start,0),'seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_ridge = classifier.predict(X_test_ridge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.99      0.87      7766\n",
      "           1       0.18      0.00      0.00      1823\n",
      "           2       0.53      0.33      0.41      4565\n",
      "           3       0.86      0.00      0.01      1528\n",
      "           4       0.36      0.01      0.02      2120\n",
      "           5       0.23      0.00      0.01      1872\n",
      "           6       0.88      0.08      0.14       743\n",
      "\n",
      "   micro avg       0.71      0.46      0.56     20417\n",
      "   macro avg       0.54      0.20      0.21     20417\n",
      "weighted avg       0.58      0.46      0.43     20417\n",
      " samples avg       0.74      0.51      0.56     20417\n",
      "\n",
      "Classification Report for Ridge Classification\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning:\n",
      "\n",
      "Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(classification_report(y_test_all, y_pred_ridge))\n",
    "   \n",
    "    \n",
    "print(\"Classification Report for Ridge Classification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rock                 0.759511\n",
       "singer-songwriter    0.178289\n",
       "pop                  0.446455\n",
       "metal                0.149438\n",
       "folk                 0.207335\n",
       "country              0.183081\n",
       "hip hop / rap        0.072665\n",
       "dtype: float64"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#proportion of 1s in each genre column\n",
    "y_test_all.sum()/len(y_test_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       null     ridge  difference\n",
      "rock               0.759511  0.763469    0.003958\n",
      "singer-songwriter  0.821711  0.839492    0.017781\n",
      "pop                0.553545  0.535308   -0.018237\n",
      "metal              0.850562  0.869209    0.018647\n",
      "folk               0.792665  0.806578    0.013913\n",
      "country            0.816919  0.832828    0.015909\n",
      "hip hop / rap      0.927335  0.942559    0.015224\n"
     ]
    }
   ],
   "source": [
    "#y_pred_ridge vs y_test\n",
    "\n",
    "acc = []\n",
    "\n",
    "for i in range(0,7):\n",
    "    check = y_pred_ridge[:,i] == np.array(y_test_all.iloc[:,i])\n",
    "    accuracy = check.sum()/len(check)\n",
    "    acc.append(accuracy)\n",
    "    \n",
    "comp = pd.DataFrame(y_test_all.sum()/len(y_test_all)).rename(columns = {0:'null'})\n",
    "comp['ridge'] = acc\n",
    "comp.iloc[1:,0] = 1-comp.iloc[1:,0]\n",
    "comp['ridge'] = comp['ridge'].divide(10000)\n",
    "comp['difference'] = (comp['ridge']- comp['null'])\n",
    "\n",
    "\n",
    "print(comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dir(RidgeClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dir(BinaryRelevance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training time taken:  5.0 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:1978: FutureWarning:\n",
      "\n",
      "The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'classifier': RidgeClassifier(alpha=0.001, class_weight=None, copy_X=True, fit_intercept=True,\n",
      "                max_iter=None, normalize=False, random_state=None,\n",
      "                solver='auto', tol=0.001), 'classifier__alpha': 0.001} 0.2358550540368722\n"
     ]
    }
   ],
   "source": [
    "from skmultilearn.problem_transform import BinaryRelevance\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import time\n",
    "\n",
    "start=time.time()\n",
    "classifier = BinaryRelevance(\n",
    "    classifier = RidgeClassifier(),\n",
    "    require_dense = [False, True]\n",
    ")\n",
    "\n",
    "classifier.fit(X_train_ridge, y_train_all_ridge)\n",
    "\n",
    "print('training time taken: ',round(time.time()-start,0),'seconds')\n",
    "\n",
    "parameters = [\n",
    "    {\n",
    "        'classifier': [RidgeClassifier()],\n",
    "        'classifier__alpha': [0.001, 0.0001],\n",
    "    },\n",
    "]\n",
    "\n",
    "clf = GridSearchCV(BinaryRelevance(), parameters, scoring='accuracy')\n",
    "clf.fit(X_train_ridge, y_train_ridge)\n",
    "\n",
    "print (clf.best_params_, clf.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training time taken:  0.0 seconds\n"
     ]
    }
   ],
   "source": [
    "from skmultilearn.problem_transform import BinaryRelevance\n",
    "import time\n",
    "\n",
    "start=time.time()\n",
    "classifier = BinaryRelevance(\n",
    "    classifier = RidgeClassifier(alpha=0.001, class_weight=None, copy_X=True, fit_intercept=True,\n",
    "                max_iter=None, normalize=False, random_state=None,\n",
    "                solver='auto', tol=0.001)\n",
    ")\n",
    "    \n",
    "classifier.fit(X_train_ridge, y_train_all_ridge)\n",
    "\n",
    "print('training time taken: ',round(time.time()-start,0),'seconds')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_ridge2 = classifier.predict(X_test_ridge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.99      0.87      7766\n",
      "           1       0.18      0.00      0.00      1823\n",
      "           2       0.53      0.33      0.41      4565\n",
      "           3       0.86      0.00      0.01      1528\n",
      "           4       0.35      0.01      0.02      2120\n",
      "           5       0.23      0.01      0.01      1872\n",
      "           6       0.88      0.08      0.14       743\n",
      "\n",
      "   micro avg       0.71      0.45      0.56     20417\n",
      "   macro avg       0.54      0.20      0.21     20417\n",
      "weighted avg       0.58      0.45      0.43     20417\n",
      " samples avg       0.74      0.51      0.56     20417\n",
      "\n",
      "Classification Report for Ridge Classification\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning:\n",
      "\n",
      "Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(classification_report(y_test_all, y_pred_ridge2))\n",
    "   \n",
    "    \n",
    "print(\"Classification Report for Ridge Classification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       null     ridge  difference\n",
      "rock               0.759511  0.763676    0.004165\n",
      "singer-songwriter  0.821711  0.839492    0.017781\n",
      "pop                0.553545  0.535576   -0.017970\n",
      "metal              0.850562  0.869209    0.018647\n",
      "folk               0.792665  0.806520    0.013855\n",
      "country            0.816919  0.832574    0.015655\n",
      "hip hop / rap      0.927335  0.942559    0.015224\n"
     ]
    }
   ],
   "source": [
    "#y_pred_ridge vs y_test\n",
    "\n",
    "acc = []\n",
    "\n",
    "for i in range(0,7):\n",
    "    check = y_pred_ridge2[:,i] == np.array(y_test_all.iloc[:,i])\n",
    "    accuracy = check.sum()/len(check)\n",
    "    acc.append(accuracy)\n",
    "    \n",
    "comp = pd.DataFrame(y_test_all.sum()/len(y_test_all)).rename(columns = {0:'null'})\n",
    "comp['ridge'] = acc\n",
    "comp.iloc[1:,0] = 1-comp.iloc[1:,0]\n",
    "comp['ridge'] = comp['ridge'].divide(10000)\n",
    "comp['difference'] = (comp['ridge']- comp['null'])\n",
    "\n",
    "\n",
    "print(comp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 2 -   K-Nearest Neighbor\n",
    "\n",
    "## I. Adapted Algorithms - MLkNN()\n",
    "\n",
    "Multi-label k-nearest neighbour (MLkNN ) is one of the most widely cited\n",
    "algorithm adaptation approaches. MLkNN is essentially a binary relevance algorithm, which acts on the labels individually, but instead of applying the standard k-nearest neighbour algorithm directly, it combines it with the maximum a posteriori principle. \n",
    "\n",
    "\n",
    "* optimal parameters via GridSearch:\n",
    "  * {'k': 4, 's': 0.5} 0.4280822442015816\n",
    "  \n",
    "\n",
    "* The Accuracy Score is: 0.12948655256723715\n",
    "* The Zero One Loss is: 0.8705134474327628\n",
    "* The Hamming Loss is: 0.2733496332518337"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rock                 0.759511\n",
       "singer-songwriter    0.178289\n",
       "pop                  0.446455\n",
       "metal                0.149438\n",
       "folk                 0.207335\n",
       "country              0.183081\n",
       "hip hop / rap        0.072665\n",
       "dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#proportion of 1s in each genre column\n",
    "y_test_all.sum()/len(y_test_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 0 ... 1 0 0]\n",
      " [1 0 1 ... 0 0 0]\n",
      " [0 0 1 ... 0 1 0]\n",
      " ...\n",
      " [1 0 0 ... 0 0 0]\n",
      " [1 0 1 ... 0 0 0]\n",
      " [1 0 1 ... 1 0 0]]\n"
     ]
    }
   ],
   "source": [
    "y_train_all_mlknn = y_train_all.rename_axis('ID').values #turning into numpy array\n",
    "X_train = np.asarray(X_train)\n",
    "X_test = np.asarray(X_test)\n",
    "\n",
    "\n",
    "\n",
    "print(y_train_all_mlknn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# have to give MLkNN a numpy array so "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#import data\n",
    "X_train = pd.read_pickle('veclyrics_doc2vec_train.pkl')\n",
    "X_test = pd.read_pickle('veclyrics_doc2vec_test.pkl')\n",
    "y_train_all = pd.read_pickle('response_doc2vec_train.pkl')\n",
    "y_test_all = pd.read_pickle('response_doc2vec_test.pkl')\n",
    "y_train_all = y_train_all.iloc[:,3:10]\n",
    "y_test_all = y_test_all.iloc[:,3:10]\n",
    "y_train_one = y_train_all.iloc[:,0]\n",
    "y_test_one = y_test_all.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_MLkNN50 = y_train_all\n",
    "y_test_MLkNN = y_test_all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.asarray(X_train)\n",
    "#y_train_MLkNN50 = y_train_MLkNN50.rename_axis('ID').values #turning df into numpy array\n",
    "y_train_MLkNN50 = np.asarray(y_train_MLkNN50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n",
      "[CV] k=10, s=0.5 .....................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ......................... k=10, s=0.5, score=0.406, total= 2.6min\n",
      "[CV] k=10, s=0.5 .....................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  2.6min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ......................... k=10, s=0.5, score=0.393, total= 2.7min\n",
      "[CV] k=10, s=0.5 .....................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  5.3min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ......................... k=10, s=0.5, score=0.396, total= 2.8min\n",
      "[CV] k=10, s=0.7 .....................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:  8.0min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ......................... k=10, s=0.7, score=0.406, total= 2.6min\n",
      "[CV] k=10, s=0.7 .....................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed: 10.6min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ......................... k=10, s=0.7, score=0.393, total= 2.7min\n",
      "[CV] k=10, s=0.7 .....................................................\n",
      "[CV] ......................... k=10, s=0.7, score=0.396, total= 2.9min\n",
      "[CV] k=10, s=1.0 .....................................................\n",
      "[CV] ......................... k=10, s=1.0, score=0.406, total= 2.7min\n",
      "[CV] k=10, s=1.0 .....................................................\n",
      "[CV] ......................... k=10, s=1.0, score=0.393, total= 2.5min\n",
      "[CV] k=10, s=1.0 .....................................................\n",
      "[CV] ......................... k=10, s=1.0, score=0.396, total= 2.5min\n",
      "[CV] k=20, s=0.5 .....................................................\n",
      "[CV] ......................... k=20, s=0.5, score=0.385, total= 2.8min\n",
      "[CV] k=20, s=0.5 .....................................................\n",
      "[CV] ......................... k=20, s=0.5, score=0.385, total= 2.8min\n",
      "[CV] k=20, s=0.5 .....................................................\n",
      "[CV] ......................... k=20, s=0.5, score=0.383, total= 2.8min\n",
      "[CV] k=20, s=0.7 .....................................................\n",
      "[CV] ......................... k=20, s=0.7, score=0.385, total= 2.6min\n",
      "[CV] k=20, s=0.7 .....................................................\n",
      "[CV] ......................... k=20, s=0.7, score=0.385, total= 2.6min\n",
      "[CV] k=20, s=0.7 .....................................................\n",
      "[CV] ......................... k=20, s=0.7, score=0.383, total= 2.6min\n",
      "[CV] k=20, s=1.0 .....................................................\n",
      "[CV] ......................... k=20, s=1.0, score=0.385, total= 2.7min\n",
      "[CV] k=20, s=1.0 .....................................................\n",
      "[CV] ......................... k=20, s=1.0, score=0.385, total= 2.6min\n",
      "[CV] k=20, s=1.0 .....................................................\n",
      "[CV] ......................... k=20, s=1.0, score=0.383, total= 2.7min\n",
      "[CV] k=30, s=0.5 .....................................................\n",
      "[CV] ......................... k=30, s=0.5, score=0.394, total= 2.9min\n",
      "[CV] k=30, s=0.5 .....................................................\n",
      "[CV] ......................... k=30, s=0.5, score=0.380, total= 2.8min\n",
      "[CV] k=30, s=0.5 .....................................................\n",
      "[CV] ......................... k=30, s=0.5, score=0.378, total= 2.8min\n",
      "[CV] k=30, s=0.7 .....................................................\n",
      "[CV] ......................... k=30, s=0.7, score=0.394, total= 2.7min\n",
      "[CV] k=30, s=0.7 .....................................................\n",
      "[CV] ......................... k=30, s=0.7, score=0.380, total= 2.7min\n",
      "[CV] k=30, s=0.7 .....................................................\n",
      "[CV] ......................... k=30, s=0.7, score=0.378, total= 2.8min\n",
      "[CV] k=30, s=1.0 .....................................................\n",
      "[CV] ......................... k=30, s=1.0, score=0.394, total= 2.7min\n",
      "[CV] k=30, s=1.0 .....................................................\n",
      "[CV] ......................... k=30, s=1.0, score=0.380, total= 2.7min\n",
      "[CV] k=30, s=1.0 .....................................................\n",
      "[CV] ......................... k=30, s=1.0, score=0.378, total= 2.7min\n",
      "[CV] k=40, s=0.5 .....................................................\n",
      "[CV] ......................... k=40, s=0.5, score=0.392, total= 2.8min\n",
      "[CV] k=40, s=0.5 .....................................................\n",
      "[CV] ......................... k=40, s=0.5, score=0.376, total= 2.7min\n",
      "[CV] k=40, s=0.5 .....................................................\n",
      "[CV] ......................... k=40, s=0.5, score=0.390, total= 2.7min\n",
      "[CV] k=40, s=0.7 .....................................................\n",
      "[CV] ......................... k=40, s=0.7, score=0.392, total= 2.8min\n",
      "[CV] k=40, s=0.7 .....................................................\n",
      "[CV] ......................... k=40, s=0.7, score=0.376, total= 3.1min\n",
      "[CV] k=40, s=0.7 .....................................................\n",
      "[CV] ......................... k=40, s=0.7, score=0.390, total= 2.8min\n",
      "[CV] k=40, s=1.0 .....................................................\n",
      "[CV] ......................... k=40, s=1.0, score=0.392, total= 2.7min\n",
      "[CV] k=40, s=1.0 .....................................................\n",
      "[CV] ......................... k=40, s=1.0, score=0.376, total= 2.7min\n",
      "[CV] k=40, s=1.0 .....................................................\n",
      "[CV] ......................... k=40, s=1.0, score=0.390, total= 2.7min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  36 out of  36 | elapsed: 98.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'k': 10, 's': 0.5} 0.39829904622016976\n"
     ]
    }
   ],
   "source": [
    "from skmultilearn.adapt import MLkNN\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameters = {'k': range(10,50,10), 's': [0.5, 0.7, 1.0]}\n",
    "\n",
    "clf = GridSearchCV(MLkNN(), parameters, scoring='f1_macro', verbose = 5)\n",
    "clf.fit(X_train, y_train_MLkNN50)\n",
    "\n",
    "print (clf.best_params_, clf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# took 98.1 min\n",
    "# 36 fits\n",
    "# best from 10 to 40 was k = 10, s = 0.5\n",
    "# 'k': 10, 's': 0.5} 0.39829904622016976"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:1978: FutureWarning:\n",
      "\n",
      "The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "[CV] k=3, s=0.5 ......................................................\n",
      "[CV] .......................... k=3, s=0.5, score=0.414, total= 2.6min\n",
      "[CV] k=3, s=0.5 ......................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  2.6min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .......................... k=3, s=0.5, score=0.414, total= 2.5min\n",
      "[CV] k=3, s=0.5 ......................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  5.2min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .......................... k=3, s=0.5, score=0.411, total= 2.5min\n",
      "[CV] k=3, s=1.0 ......................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:  7.7min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .......................... k=3, s=1.0, score=0.414, total= 2.4min\n",
      "[CV] k=3, s=1.0 ......................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed: 10.1min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .......................... k=3, s=1.0, score=0.414, total= 2.4min\n",
      "[CV] k=3, s=1.0 ......................................................\n",
      "[CV] .......................... k=3, s=1.0, score=0.411, total= 2.4min\n",
      "[CV] k=4, s=0.5 ......................................................\n",
      "[CV] .......................... k=4, s=0.5, score=0.429, total= 2.4min\n",
      "[CV] k=4, s=0.5 ......................................................\n",
      "[CV] .......................... k=4, s=0.5, score=0.404, total= 2.5min\n",
      "[CV] k=4, s=0.5 ......................................................\n",
      "[CV] .......................... k=4, s=0.5, score=0.452, total= 2.5min\n",
      "[CV] k=4, s=1.0 ......................................................\n",
      "[CV] .......................... k=4, s=1.0, score=0.429, total= 2.4min\n",
      "[CV] k=4, s=1.0 ......................................................\n",
      "[CV] .......................... k=4, s=1.0, score=0.404, total= 2.5min\n",
      "[CV] k=4, s=1.0 ......................................................\n",
      "[CV] .......................... k=4, s=1.0, score=0.452, total= 2.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  12 out of  12 | elapsed: 29.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'k': 4, 's': 0.5} 0.4280822442015816\n"
     ]
    }
   ],
   "source": [
    "from skmultilearn.adapt import MLkNN\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameters = {'k': range(3,5), 's': [0.5, 1.0]}\n",
    "\n",
    "clf = GridSearchCV(MLkNN(), parameters, scoring='f1_macro', verbose = 5)\n",
    "clf.fit(X_train, y_train_MLkNN50)\n",
    "\n",
    "print (clf.best_params_, clf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimal parmaeters {'k': 4, 's': 0.5} 0.4280822442015816\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_mlknn = y_train_all\n",
    "y_test_mlknn = y_test_all\n",
    "X_train_mlknn = np.asarray(X_train)\n",
    "y_train_mlknn = np.asarray(y_train_mlknn)\n",
    "X_test_mlknn = np.asarray(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlknn = MLkNN(k=4, s=0.5)\n",
    "\n",
    "begin = dt.datetime.now()\n",
    "\n",
    "mlknn.fit(X_train_mlknn, y_train_mlknn)\n",
    "y_pred_mlknn = mlknn.predict(X_test_mlknn)\n",
    "y_pred_train_mlknn = mlknn.predict(X_train_mlknn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run time: 0:09:49.191633; training accuracy: 0.3832216734314636; training precision: 0.7519839057126109; training F1: 0.7232767293857527. testing accuracy: 0.12948655256723715; testing precision: 0.4907048179906204; testing F1: 0.48961869820420817.\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"Run time: {};\".format(dt.datetime.now() - begin),\n",
    "    \"training accuracy: {};\".format(accuracy_score(y_train_mlknn, y_pred_train_mlknn)),\n",
    "    \"training precision: {};\".format(precision_score(y_train_mlknn, y_pred_train_mlknn, average = 'weighted')),\n",
    "    \"training F1: {}.\".format(f1_score(y_train_mlknn, y_pred_train_mlknn, average = 'weighted')),\n",
    "    \"testing accuracy: {};\".format(accuracy_score(y_test_mlknn, y_pred_mlknn)),\n",
    "    \"testing precision: {};\".format(precision_score(y_test_mlknn, y_pred_mlknn, average = 'weighted')),\n",
    "    \"testing F1: {}.\".format(f1_score(y_test_mlknn, y_pred_mlknn, average = 'weighted'))\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import zero_one_loss\n",
    "from sklearn.metrics import hamming_loss\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def eval_multi_metrics(ytrue, ypred):\n",
    "    print (\"The Accuracy Score is:\",accuracy_score(ytrue, ypred))\n",
    "    print (\"The Zero One Loss is:\",zero_one_loss(ytrue, ypred))\n",
    "    print (\"The Hamming Loss is:\",hamming_loss(ytrue, ypred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "     \"\"\"\n",
    "     INPUT:\n",
    "    :param ytrue: ground truth\n",
    "    :param ypred: predictions\n",
    "\n",
    "     \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Accuracy Score is: 0.12948655256723715\n",
      "The Zero One Loss is: 0.8705134474327628\n",
      "The Hamming Loss is: 0.27334963325183376\n"
     ]
    }
   ],
   "source": [
    "eval_multi_metrics(y_test_mlknn, y_pred_mlknn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 2 -   K-Nearest Neighbors\n",
    "\n",
    "## II. Problem Transformation | Binary Relevance - BRkNNaClassifier()\n",
    "\n",
    "* optimal parameters - {'k': 5} 0.39338534264811964\n",
    "* accuracy score: 0.15980440097799511\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_BRkNN = y_train_all\n",
    "y_test_BRkNN = y_test_all\n",
    "X_train_BRkNN = np.asarray(X_train)\n",
    "y_train_BRkNN = np.asarray(y_train_BRkNN)\n",
    "X_test_BRkNN = np.asarray(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:1978: FutureWarning:\n",
      "\n",
      "The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
      "[CV] k=5 .............................................................\n",
      "[CV] ................................. k=5, score=0.397, total=  46.6s\n",
      "[CV] k=5 .............................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   46.6s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................. k=5, score=0.389, total=  46.4s\n",
      "[CV] k=5 .............................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  1.6min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................. k=5, score=0.394, total=  47.6s\n",
      "[CV] k=6 .............................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:  2.3min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................. k=6, score=0.334, total=  46.6s\n",
      "[CV] k=6 .............................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:  3.1min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................. k=6, score=0.326, total=  46.7s\n",
      "[CV] k=6 .............................................................\n",
      "[CV] ................................. k=6, score=0.330, total=  46.5s\n",
      "[CV] k=7 .............................................................\n",
      "[CV] ................................. k=7, score=0.377, total=  46.3s\n",
      "[CV] k=7 .............................................................\n",
      "[CV] ................................. k=7, score=0.373, total=  48.4s\n",
      "[CV] k=7 .............................................................\n",
      "[CV] ................................. k=7, score=0.378, total=  47.9s\n",
      "{'k': 5} 0.39338534264811964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:  7.1min finished\n"
     ]
    }
   ],
   "source": [
    "from skmultilearn.adapt import BRkNNaClassifier\n",
    "\n",
    "\n",
    "from skmultilearn.adapt import BRkNNaClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameters = {'k': range(5,8)}\n",
    "score = 'f1_macro'\n",
    "\n",
    "clf = GridSearchCV(BRkNNaClassifier(), parameters, scoring=score, verbose = 5)\n",
    "clf.fit(X_train, y_train_BRkNN)\n",
    "\n",
    "print(clf.best_params_, clf.best_score_) #{'k': 5} 0.39338534264811964\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'k': 5} 0.39338534264811964\n"
     ]
    }
   ],
   "source": [
    "print(clf.best_params_, clf.best_score_) #{'k': 5} 0.39338534264811964\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "brknn = BRkNNaClassifier(k=5)\n",
    "\n",
    "begin = dt.datetime.now()\n",
    "\n",
    "brknn.fit(X_train_BRkNN, y_train_BRkNN)\n",
    "y_pred_BRkNN = brknn.predict(X_test_BRkNN)\n",
    "y_pred_train_BRkNN = brknn.predict(X_train_BRkNN)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       null     BRkNN  difference\n",
      "rock               0.759511  0.745459   -0.014052\n",
      "singer-songwriter  0.821711  0.803332   -0.018380\n",
      "pop                0.553545  0.524395   -0.029150\n",
      "metal              0.850562  0.846773   -0.003789\n",
      "folk               0.792665  0.750504   -0.042161\n",
      "country            0.816919  0.800883   -0.016037\n",
      "hip hop / rap      0.927335  0.942132    0.014797\n"
     ]
    }
   ],
   "source": [
    "\n",
    "acc = []\n",
    "\n",
    "for i in range(0,7):\n",
    "    check = y_pred_BRkNN[:,i] == np.array(y_test_all.iloc[:,i])\n",
    "    accuracy = check.sum()/len(check)\n",
    "    acc.append(accuracy)\n",
    "    \n",
    "comp = pd.DataFrame(y_test_all.sum()/len(y_test_all)).rename(columns = {0:'null'})\n",
    "comp['BRkNN'] = acc\n",
    "comp.iloc[1:,0] = 1-comp.iloc[1:,0]\n",
    "comp['BRkNN'] = comp['BRkNN'].divide(10000)\n",
    "comp['difference'] = (comp['BRkNN']- comp['null'])\n",
    "\n",
    "\n",
    "print(comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15980440097799511"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test_BRkNN,y_pred_BRkNN) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 3 - Multinomial Naive Bayes\n",
    "\n",
    "## I. Problem Transformation | Binary Relevance - MultinomialNB()\n",
    "\n",
    "* Does not accept negative inputs so used MinMaxScaler()\n",
    "* Default parameters\n",
    "* accuracy score: 0.1852322738386308\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_MNB_BR = y_train_all\n",
    "y_test_MNB_BR = y_test_all\n",
    "X_train_MNB_BR = X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "scaler.fit(X_train_MNB_BR)\n",
    "\n",
    "X_train_MNB_BR = scaler.transform(X_train_MNB_BR)\n",
    "\n",
    "X_test_MNB_BR = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1852322738386308"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using binary relevance\n",
    "from skmultilearn.problem_transform import BinaryRelevance\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# initialize binary relevance multi-label classifier\n",
    "# with a gaussian naive bayes base classifier\n",
    "clf_MNB_BR = BinaryRelevance(MultinomialNB())\n",
    "\n",
    "# train\n",
    "clf_MNB_BR.fit(X_train_MNB_BR, y_train_MNB_BR)\n",
    "\n",
    "# predict\n",
    "predictions_MNB_BR = clf_MNB_BR.predict(X_test_MNB_BR)\n",
    "\n",
    "# accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test_MNB_BR,predictions_MNB_BR) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " --- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 3 - Multinomial Naive Bayes\n",
    "\n",
    "## II. Problem Transformation | Classifier Chains - MultinomialNB()\n",
    "\n",
    "* Does not accept negative inputs so used MinMaxScaler()\n",
    "* Default parameters\n",
    "* accuracy score: 0.1852322738386308 (same as BinaryRelevance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOT RUN YET\n",
    "\n",
    "y_train_MNB_cc = y_train_all\n",
    "y_test_MNB_cc = y_test_all\n",
    "X_train_MNB_cc = X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "scaler.fit(X_train_MNB_cc)\n",
    "\n",
    "X_train_MNB_cc = scaler.transform(X_train_MNB_cc)\n",
    "X_test_MNB_cc = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1852322738386308"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using classifier chains\n",
    "from skmultilearn.problem_transform import ClassifierChain\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# initialize classifier chains multi-label classifier\n",
    "# with a gaussian naive bayes base classifier\n",
    "clf_MNB_cc = LabelPowerset(MultinomialNB())\n",
    "\n",
    "# train\n",
    "clf_MNB_cc.fit(X_train_MNB_cc, y_train_MNB_cc)\n",
    "\n",
    "# predict\n",
    "predictions_MNB_cc = clf_MNB_cc.predict(X_test_MNB_cc)\n",
    "\n",
    "accuracy_score(y_test_MNB_cc,predictions_MNB_cc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 3 - Multinomial Naive Bayes\n",
    "\n",
    "## III. Problem Transformation | Label Powerset - MultinomialNB()\n",
    "\n",
    "* Does not accept negative inputs so used MinMaxScaler()\n",
    "* Default parameters\n",
    "* accuracy score: 0.1852322738386308\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_train_MNB_LP = y_train_all\n",
    "y_test_MNB_LP = y_test_all\n",
    "X_train_MNB_LP = X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "scaler.fit(X_train_MNB_LP)\n",
    "\n",
    "X_train_MNB_LP = scaler.transform(X_train_MNB_LP)\n",
    "X_test_MNB_LP = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1852322738386308"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using Label Powerset\n",
    "from skmultilearn.problem_transform import LabelPowerset\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# NOT RUN YET\n",
    "\n",
    "# initialize Label Powerset multi-label classifier\n",
    "# with a gaussian naive bayes base classifier\n",
    "clf_MNB_LP = LabelPowerset(MultinomialNB())\n",
    "\n",
    "# train\n",
    "clf_MNB_LP.fit(X_train_MNB_LP, y_train_MNB_LP)\n",
    "\n",
    "# predict\n",
    "predictions_MNB_LP = clf_MNB_LP.predict(X_test_MNB_LP)\n",
    "\n",
    "accuracy_score(y_test_MNB_LP,predictions_MNB_LP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes on K Nearest Neighbors\n",
    "\n",
    "* KNN neighbors is a package of the sklearn, which provides functionalities for nearest neighbor classifiers both for unsupervised and supervised learning.\n",
    "\n",
    "* Input must be Numpy arrays or scipy.sparse matrices\n",
    "\n",
    "### KNeighborsClassifier\n",
    "\n",
    "KNeighborsClassifier is based on the k nearest neighbors of a sample, which has to be classified. The number 'k' is an integer value specified by the user. This is the most frequently used classifiers of both algorithms.\n",
    "\n",
    "### RadiusNeighborsClassifier (not used)\n",
    "\n",
    "is based on the number of neighbors within a fixed radius r for each sample which has to be classified. 'r' is float value specified by the user. This classifier is less often used.\n",
    "There is no general way to define an optimal value for 'k'. This value depends on the data. As a general rule we can say that increasing 'k' reduces the noise but on the other hand makes the boundaries less distinct.\n",
    "\n",
    "\n",
    "### Scaling\n",
    "\n",
    " - You dont have to scale the one hot encoded features.\n",
    "\n",
    " - MinMaxScaler: One of the major reason is that your features can't have negative values and it could be sparse. From Documentation: The motivation to use this scaling include robustness to very small standard deviations of features and preserving zero entries in sparse data.\n",
    "\n",
    " - if your numerical variable has a huge variance, then go for RobustScaler or StandardScaler.\n",
    "\n",
    " - TfidfVectorizer does the l2 normalization by default.\n",
    " \n",
    "---\n",
    "\n",
    "## Parameter Tuning Notes\n",
    "\n",
    "### Specifically KNN Parameters\n",
    "\n",
    "#### Comparing Error Rate with the K Value\n",
    "\n",
    "* There is no way to know beforehand which value of K that yields the best results in the first go. So randomly choose 5 as the K value.\n",
    "\n",
    "* One way to find the best value of K is to plot the graph of K value and the corresponding error rate for the dataset-- however this is impossible with multiple labels so the suggested route is to find the best K using this method assuming single classification. How: calculate the mean of error for all the predicted values where K ranges from 1 to 40(or whatever number). \n",
    "\n",
    "* see sklearn docs for all parameters, only ones we used were k (number of neighbors) and s (smoothing)\n",
    "\n",
    " ### Specifically for MLkNN | s - smoothing parameter\n",
    " \n",
    "* s is a smoothing parameter controlling the strength of uniform prior.\n",
    " \n",
    "* when s = 1: Laplace Smoothing. In statistics, Laplace Smoothing is a technique to smooth categorical data. Laplace Smoothing is introduced to solve the problem of zero probability. from 0 to 1.\n",
    " \n",
    " \n",
    " ### Additional Multi Label kNNs (not used but for reference)\n",
    "\n",
    " * Dependent MLkNN (DMLkNN ) follows the same principle as MLkNN but incorporates all of the labels while deciding the probability for each label, therefore taking label associations into account.\n",
    "\n",
    " * IBLR-ML is another modification of the k-nearest neighbour algorithm. It finds the nearest neighbours of the data point to be labeled, and trains a logistic regression model for each label using the labels of these neighbourhood points as features, thus taking the label associations into account. \n",
    "\n",
    " ---\n",
    " \n",
    "\n",
    "## Evaluation Notes\n",
    "\n",
    "   * For evaluating an algorithm, confusion matrix, precision, recall and f1 score are the most commonly used metrics. The confusion_matrix and classification_report methods of the sklearn.metrics can be used to calculate these metrics. \n",
    "    \n",
    "* Hamming loss measures how well the classifier predicts each of the labels, averaged over samples, then over labels\n",
    "\n",
    "* accuracy score measures how well the classifier predicts label combinations, averaged over samples\n",
    "\n",
    "* jaccard similarity measures the proportion of predicted labels for a sample to its correct assignment, averaged over samples\n",
    "\n",
    "* F1 score measures a weighted average of precision and recall, where both have the same impact on the score\n",
    "\n",
    "* AUC is useful as a single number summary of classifier performance\n",
    "\n",
    "  * Higher value = better classifier\n",
    "\n",
    "* If you randomly chose one positive and one negative observation, AUC represents the likelihood that your classifier will assign a higher predicted probability to the positive observation\n",
    "\n",
    "* AUC is useful even when there is high class imbalance (unlike classification accuracy)\n",
    "\n",
    "\n",
    " ***\n",
    "\n",
    "References:\n",
    "\n",
    "* The multi-label methods used in this work were implemented by making use of code created by Min-Ling Zhang http://lup.lub.lu.se/luur/download/func=downloadFile&recordOId=8933695&fileOId=8933698\n",
    " \n",
    " \n",
    "* https://cs.nju.edu.cn/zhouzh/zhouzh.files/publication/pr07.pdf\n",
    "\n",
    "* https://stackabuse.com/k-nearest-neighbors-algorithm-in-python-and-scikit-learn/\n",
    "\n",
    "* https://www.python-course.eu/k_nearest_neighbor_classifier.php\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
