{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "import re\n",
    "import random\n",
    "from scipy import sparse\n",
    "from scipy.sparse import csr_matrix, vstack\n",
    "from textblob import TextBlob\n",
    "from langdetect import detect_langs\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.stem.porter import *\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from gensim.models import Word2Vec\n",
    "import multiprocessing\n",
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "from langdetect import detect\n",
    "# from wordcloud import WordCloud, STOPWORDS\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB, ComplementNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import svm\n",
    "import plotly.graph_objects as go\n",
    "# from better_profanity import profanity\n",
    "import string\n",
    "\n",
    "\n",
    "# added from here\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "import re\n",
    "from gensim import utils\n",
    "from gensim.models.doc2vec import LabeledSentence\n",
    "from gensim.models import Doc2Vec\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import svm\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import nltk\n",
    "import sklearn\n",
    "import nltk.collocations \n",
    "from nltk import FreqDist, word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import string, re\n",
    "import urllib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#import xgboost as xgb\n",
    "#nltk.download('punkt')\n",
    "#nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('words')\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "import numpy as np\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import Ridge #import ridge \n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import neighbors \n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RidgeClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Note on Multi-Label classification\n",
    "\n",
    "Basically, there are three \"methods/ways\" to solve a multi-label classification problem:\n",
    "\n",
    "   ### 1) Problem Transformation\n",
    "   Problem Transformation: transforms our multi-label problem into single-label problem(s). This method can be carried out in three different ways as:\n",
    "     * Binary Relevance\n",
    "     * Classifier Chains\n",
    "     * Label Powerset\n",
    "   ### 2) Adapted Algorithm\n",
    "   Adapted Algorithm: adapts the algorithm to directly perform multi-label classification, rather than transforming the problem into different subsets of problems.\n",
    "     * e.g. kNN's multi-label adaptation is MLkNN. \n",
    "     \n",
    "   ### 3) Ensemble approaches\n",
    "   Ensemble Approaches: Ensemble apparently always produces better results. \n",
    "     * Scikit-Multilearn library provides different ensembling classification functions. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 1:  Ridge Classifier \n",
    "\n",
    "## Problem Transformation- BinaryRelevance\n",
    "\n",
    " * Ridge Classifier doesn't support multi-label classification\n",
    " * Therefore, you have to implement one of the 3 multi label classification methods\n",
    " * We chose to use BinaryRelevance which is a type of \"Problem Transformation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import data\n",
    "X_train = pd.read_pickle('veclyrics_doc2vec_train.pkl')\n",
    "X_test = pd.read_pickle('veclyrics_doc2vec_test.pkl')\n",
    "y_train_all = pd.read_pickle('response_doc2vec_train.pkl')\n",
    "y_test_all = pd.read_pickle('response_doc2vec_test.pkl')\n",
    "y_train_all = y_train_all.iloc[:,3:10]\n",
    "y_test_all = y_test_all.iloc[:,3:10]\n",
    "y_train_one = y_train_all.iloc[:,0]\n",
    "y_test_one = y_test_all.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_ridge = np.asarray(y_train_all)\n",
    "X_train_ridge = np.asarray(X_train)\n",
    "X_test_ridge = np.asarray(X_test)\n",
    "y_test_ridge = np.asarray(y_test_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training time taken:  5.0 seconds\n"
     ]
    }
   ],
   "source": [
    "from skmultilearn.problem_transform import BinaryRelevance\n",
    "import time\n",
    "\n",
    "start=time.time()\n",
    "classifier = BinaryRelevance(\n",
    "    classifier = RidgeClassifier(),\n",
    "    require_dense = [False, True]\n",
    ")\n",
    "\n",
    "classifier.fit(X_train_ridge, y_train_all_ridge)\n",
    "\n",
    "print('training time taken: ',round(time.time()-start,0),'seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_ridge = classifier.predict(X_test_ridge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.99      0.87      7766\n",
      "           1       0.18      0.00      0.00      1823\n",
      "           2       0.53      0.33      0.41      4565\n",
      "           3       0.86      0.00      0.01      1528\n",
      "           4       0.36      0.01      0.02      2120\n",
      "           5       0.23      0.00      0.01      1872\n",
      "           6       0.88      0.08      0.14       743\n",
      "\n",
      "   micro avg       0.71      0.46      0.56     20417\n",
      "   macro avg       0.54      0.20      0.21     20417\n",
      "weighted avg       0.58      0.46      0.43     20417\n",
      " samples avg       0.74      0.51      0.56     20417\n",
      "\n",
      "Classification Report for Ridge Classification\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning:\n",
      "\n",
      "Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(classification_report(y_test_all, y_pred_ridge))\n",
    "   \n",
    "    \n",
    "print(\"Classification Report for Ridge Classification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rock                 0.759511\n",
       "singer-songwriter    0.178289\n",
       "pop                  0.446455\n",
       "metal                0.149438\n",
       "folk                 0.207335\n",
       "country              0.183081\n",
       "hip hop / rap        0.072665\n",
       "dtype: float64"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#proportion of 1s in each genre column\n",
    "y_test_all.sum()/len(y_test_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       null     ridge  difference\n",
      "rock               0.759511  0.763469    0.003958\n",
      "singer-songwriter  0.821711  0.839492    0.017781\n",
      "pop                0.553545  0.535308   -0.018237\n",
      "metal              0.850562  0.869209    0.018647\n",
      "folk               0.792665  0.806578    0.013913\n",
      "country            0.816919  0.832828    0.015909\n",
      "hip hop / rap      0.927335  0.942559    0.015224\n"
     ]
    }
   ],
   "source": [
    "#y_pred_ridge vs y_test\n",
    "\n",
    "acc = []\n",
    "\n",
    "for i in range(0,7):\n",
    "    check = y_pred_ridge[:,i] == np.array(y_test_all.iloc[:,i])\n",
    "    accuracy = check.sum()/len(check)\n",
    "    acc.append(accuracy)\n",
    "    \n",
    "comp = pd.DataFrame(y_test_all.sum()/len(y_test_all)).rename(columns = {0:'null'})\n",
    "comp['ridge'] = acc\n",
    "comp.iloc[1:,0] = 1-comp.iloc[1:,0]\n",
    "comp['ridge'] = comp['ridge'].divide(10000)\n",
    "comp['difference'] = (comp['ridge']- comp['null'])\n",
    "\n",
    "\n",
    "print(comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dir(RidgeClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dir(BinaryRelevance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training time taken:  5.0 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:1978: FutureWarning:\n",
      "\n",
      "The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'classifier': RidgeClassifier(alpha=0.001, class_weight=None, copy_X=True, fit_intercept=True,\n",
      "                max_iter=None, normalize=False, random_state=None,\n",
      "                solver='auto', tol=0.001), 'classifier__alpha': 0.001} 0.2358550540368722\n"
     ]
    }
   ],
   "source": [
    "from skmultilearn.problem_transform import BinaryRelevance\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import time\n",
    "\n",
    "start=time.time()\n",
    "classifier = BinaryRelevance(\n",
    "    classifier = RidgeClassifier(),\n",
    "    require_dense = [False, True]\n",
    ")\n",
    "\n",
    "classifier.fit(X_train_ridge, y_train_all_ridge)\n",
    "\n",
    "print('training time taken: ',round(time.time()-start,0),'seconds')\n",
    "\n",
    "parameters = [\n",
    "    {\n",
    "        'classifier': [RidgeClassifier()],\n",
    "        'classifier__alpha': [0.001, 0.0001],\n",
    "    },\n",
    "]\n",
    "\n",
    "clf = GridSearchCV(BinaryRelevance(), parameters, scoring='accuracy')\n",
    "clf.fit(X_train_ridge, y_train_ridge)\n",
    "\n",
    "print (clf.best_params_, clf.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training time taken:  0.0 seconds\n"
     ]
    }
   ],
   "source": [
    "from skmultilearn.problem_transform import BinaryRelevance\n",
    "import time\n",
    "\n",
    "start=time.time()\n",
    "classifier = BinaryRelevance(\n",
    "    classifier = RidgeClassifier(alpha=0.001, class_weight=None, copy_X=True, fit_intercept=True,\n",
    "                max_iter=None, normalize=False, random_state=None,\n",
    "                solver='auto', tol=0.001)\n",
    ")\n",
    "    \n",
    "classifier.fit(X_train_ridge, y_train_all_ridge)\n",
    "\n",
    "print('training time taken: ',round(time.time()-start,0),'seconds')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_ridge2 = classifier.predict(X_test_ridge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.99      0.87      7766\n",
      "           1       0.18      0.00      0.00      1823\n",
      "           2       0.53      0.33      0.41      4565\n",
      "           3       0.86      0.00      0.01      1528\n",
      "           4       0.35      0.01      0.02      2120\n",
      "           5       0.23      0.01      0.01      1872\n",
      "           6       0.88      0.08      0.14       743\n",
      "\n",
      "   micro avg       0.71      0.45      0.56     20417\n",
      "   macro avg       0.54      0.20      0.21     20417\n",
      "weighted avg       0.58      0.45      0.43     20417\n",
      " samples avg       0.74      0.51      0.56     20417\n",
      "\n",
      "Classification Report for Ridge Classification\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning:\n",
      "\n",
      "Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(classification_report(y_test_all, y_pred_ridge2))\n",
    "   \n",
    "    \n",
    "print(\"Classification Report for Ridge Classification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       null     ridge  difference\n",
      "rock               0.759511  0.763676    0.004165\n",
      "singer-songwriter  0.821711  0.839492    0.017781\n",
      "pop                0.553545  0.535576   -0.017970\n",
      "metal              0.850562  0.869209    0.018647\n",
      "folk               0.792665  0.806520    0.013855\n",
      "country            0.816919  0.832574    0.015655\n",
      "hip hop / rap      0.927335  0.942559    0.015224\n"
     ]
    }
   ],
   "source": [
    "#y_pred_ridge vs y_test\n",
    "\n",
    "acc = []\n",
    "\n",
    "for i in range(0,7):\n",
    "    check = y_pred_ridge2[:,i] == np.array(y_test_all.iloc[:,i])\n",
    "    accuracy = check.sum()/len(check)\n",
    "    acc.append(accuracy)\n",
    "    \n",
    "comp = pd.DataFrame(y_test_all.sum()/len(y_test_all)).rename(columns = {0:'null'})\n",
    "comp['ridge'] = acc\n",
    "comp.iloc[1:,0] = 1-comp.iloc[1:,0]\n",
    "comp['ridge'] = comp['ridge'].divide(10000)\n",
    "comp['difference'] = (comp['ridge']- comp['null'])\n",
    "\n",
    "\n",
    "print(comp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes on K Nearest Neighbors\n",
    "\n",
    " * reference: \n",
    " https://stackabuse.com/k-nearest-neighbors-algorithm-in-python-and-scikit-learn/\n",
    " https://www.python-course.eu/k_nearest_neighbor_classifier.php\n",
    "\n",
    "KNN neighbors is a package of the sklearn, which provides functionalities for nearest neighbor classifiers both for unsupervised and supervised learning.\n",
    "\n",
    "((it is parametric bc u need to give it at least a K value))\n",
    "\n",
    "The classes in sklearn.neighbors can handle both Numpy arrays and scipy.sparse matrices as input. For dense matrices, a large number of possible distance metrics are supported. For sparse matrices, arbitrary Minkowski metrics are supported for searches.\n",
    "\n",
    "scikit-learn implements two different nearest neighbors classifiers:\n",
    "\n",
    "### KNeighborsClassifier\n",
    "\n",
    "is based on the k nearest neighbors of a sample, which has to be classified. The number 'k' is an integer value specified by the user. This is the most frequently used classifiers of both algorithms.\n",
    "\n",
    "### RadiusNeighborsClassifier\n",
    "\n",
    "is based on the number of neighbors within a fixed radius r for each sample which has to be classified. 'r' is float value specified by the user. This classifier is less often used.\n",
    "There is no general way to define an optimal value for 'k'. This value depends on the data. As a general rule we can say that increasing 'k' reduces the noise but on the other hand makes the boundaries less distinct.\n",
    "\n",
    "The decision based on the nearest neighbors can be reached either uniform weights, the class assigned to a query sample is calculated by a simple majority vote of the k-nearest neighbors. This does not take into account that the neighbors closer to the sample should contribute more than the ones further away. The weighting can be controlled by the weights keyword:\n",
    "\n",
    "weights = 'uniform' assigns uniform weights to each neighbor. This is also the default value.\n",
    "\n",
    "weights = 'distance' assigns weights proportional to the inverse of the distance from the query sample.\n",
    "\n",
    "It is also possible to supply a user-defined function to compute the distance.\n",
    "\n",
    "\n",
    "#### Scaling the data\n",
    "\n",
    " - MinMaxScaler: One of the major reason is that your features such as price can't have negative values and as you mentioned, it could be sparse. From Documentation: The motivation to use this scaling include robustness to very small standard deviations of features and preserving zero entries in sparse data.\n",
    "\n",
    " - if your numerical variable has a huge variance, then go for RobustScaler or StandardScaler.\n",
    "\n",
    " - You dont have to scale the one hot encoded features.\n",
    "\n",
    " - For BoW, it is important to preserve the sparsity of the data. If you apply the StandardScaler, you will lose the sparsity. You definitely have to go for MinMaxScaler. Another option would be to go for TfidfVectorizer, which does the l2 normalization by default.\n",
    " \n",
    "\n",
    "#### Comparing Error Rate with the K Value\n",
    "\n",
    "* There is no way to know beforehand which value of K that yields the best results in the first go. So randomly choose 5 as the K value.\n",
    "\n",
    "* One way to find the best value of K is to plot the graph of K value and the corresponding error rate for the dataset.\n",
    "\n",
    "* Below, is a plot of the mean error for the predicted values of test set for all the K values between 1 and 40.\n",
    "\n",
    "* To do this, we had to first calculate the mean of error for all the predicted values where K ranges from 1 and 40. \n",
    "\n",
    "\n",
    "\n",
    "## Parameter Tuning\n",
    "\n",
    "### KNN Parameters\n",
    "\n",
    " - n_neighbors \n",
    "   int, optional (default = 5)) \n",
    "   Number of neighbors to use by default for meth:'kneighbors' queries.\n",
    " \n",
    " - weights\n",
    "   str or callable, optional (default = 'uniform')\n",
    "   weight function used in prediction. Possible values:\n",
    "       - 'uniform' : uniform weights. All points in each neighborhood are weighted equally.\n",
    "       - 'distance' : weight points by the inverse of their distance. in this case, closer neighbors of a query point           will have a greater influence than neighbors which are further away.\n",
    "       - [callable] : a user-defined function which accepts an array of distances, and returns an array of the same             shape containing the weights.\n",
    "\n",
    " - algorithm\n",
    "    optional Algorithm used to compute the nearest neighbors:\n",
    "    'ball_tree' will use :class:'BallTree'\n",
    "    'kd_tree' will use :class:'KDTree'\n",
    "    'brute' will use a brute-force search.\n",
    "    'auto' will attempt to decide the most appropriate algorithm based on the values passed to :meth:'fit' method.\n",
    "     Note: fitting on sparse input will override the setting of this parameter, using brute force.\n",
    " \n",
    " - leaf_size\n",
    "    int, optional (default = 30)\n",
    "    Leaf size passed to BallTree or KDTree. This can affect the speed of the construction and query, as well as the       memory required to store the tree. The optimal value depends on the nature of the problem.\n",
    "\n",
    " - p\n",
    "    integer, optional (default = 2)\n",
    "    Power parameter for the Minkowski metric. When p = 1, this is equivalent to using manhattan_distance (l1), and       euclidean_distance (l2) for p = 2. For arbitrary p, minkowski_distance (l_p) is used.\n",
    "\n",
    " - metric\n",
    "    string or callable, default 'minkowski'\n",
    "    the distance metric to use for the tree. The default metric is minkowski, and with p=2 is equivalent to the           standard Euclidean metric. See the documentation of the DistanceMetric class for a list of available metrics.\n",
    "\n",
    " - metric_params\n",
    "   dict, optional (default = None)\n",
    "   Additional keyword arguments for the metric function.\n",
    "\n",
    " - n_jobs\n",
    "   int, optional (default = 1)\n",
    "   The number of parallel jobs to run for neighbors search. If '-1', then the number of jobs is set to the number of    CPU cores. Doesn't affect :meth:'fit' method.\n",
    "\n",
    "\n",
    "# Evaluating KNN\n",
    "\n",
    "    * For evaluating an algorithm, confusion matrix, precision, recall and f1 score are the most commonly used metrics. The confusion_matrix and classification_report methods of the sklearn.metrics can be used to calculate these metrics. \n",
    "    \n",
    "5.1.1. Generalization quality measures¶\n",
    "There are several ways to measure a classifier’s generalization quality:\n",
    "\n",
    "Hamming loss measures how well the classifier predicts each of the labels, averaged over samples, then over labels\n",
    "accuracy score measures how well the classifier predicts label combinations, averaged over samples\n",
    "\n",
    "jaccard similarity measures the proportion of predicted labels for a sample to its correct assignment, averaged over samples\n",
    "\n",
    "precision measures how many samples with ,\n",
    "\n",
    "recall measures how many samples ,\n",
    "\n",
    "F1 score measures a weighted average of precision and recall, where both have the same impact on the score\n",
    "These measures are conveniently provided by sklearn:\n",
    "\n",
    "\n",
    "#metrics.hamming_loss(y_test_all, predictions_MLkNN) # k = 5\n",
    "\n",
    "# evaluating in general\n",
    "\n",
    "* AUC is useful as a single number summary of classifier performance\n",
    "\n",
    "* Higher value = better classifier\n",
    "\n",
    "* If you randomly chose one positive and one negative observation, AUC represents the likelihood that your classifier will assign a higher predicted probability to the positive observation\n",
    "\n",
    "* AUC is useful even when there is high class imbalance (unlike classification accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adapted Algorithm- MLkNN\n",
    "\n",
    "\n",
    "Multi-label k-nearest neighbour (MLkNN ) [25] is one of the most widely cited\n",
    "algorithm adaptation approaches. MLkNN is essentially a binary relevance algorithm, which acts on the labels individually, but instead of applying the standard k-nearest neighbour algorithm directly, it combines it with the maximum a posteriori principle. \n",
    "\n",
    "Dependent MLkNN (DMLkNN ) [22] follows the same principle\n",
    "as MLkNN but incorporates all of the labels while deciding the probability for\n",
    "each label, therefore taking label associations into account.\n",
    "\n",
    "IBLR-ML [4] is another modification of the k-nearest neighbour algorithm. It finds the nearest\n",
    "neighbours of the data point to be labeled, and trains a logistic regression model\n",
    "for each label using the labels of these neighbourhood points as features, thus\n",
    "taking the label associations into account. \n",
    "\n",
    "An algorithmic performance improvement of binary relevance combined with standard k-nearest neighbour, BRkNN,\n",
    "has also been proposed [16]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rock                 0.759511\n",
       "singer-songwriter    0.178289\n",
       "pop                  0.446455\n",
       "metal                0.149438\n",
       "folk                 0.207335\n",
       "country              0.183081\n",
       "hip hop / rap        0.072665\n",
       "dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#proportion of 1s in each genre column\n",
    "y_test_all.sum()/len(y_test_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 0 ... 1 0 0]\n",
      " [1 0 1 ... 0 0 0]\n",
      " [0 0 1 ... 0 1 0]\n",
      " ...\n",
      " [1 0 0 ... 0 0 0]\n",
      " [1 0 1 ... 0 0 0]\n",
      " [1 0 1 ... 1 0 0]]\n"
     ]
    }
   ],
   "source": [
    "y_train_all_mlknn = y_train_all.rename_axis('ID').values #turning into numpy array\n",
    "X_train = np.asarray(X_train)\n",
    "X_test = np.asarray(X_test)\n",
    "\n",
    "\n",
    "\n",
    "print(y_train_all_mlknn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# have to give MLkNN a numpy array so "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-learn KNN -  Adapted Algorithm\n",
    "\n",
    "* ran grid search from k = 10 - 50 \n",
    "* returned optimal parameters:\n",
    "    {'k': 10, 's': 0.5} 0.39829904622016976\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#import data\n",
    "X_train = pd.read_pickle('veclyrics_doc2vec_train.pkl')\n",
    "X_test = pd.read_pickle('veclyrics_doc2vec_test.pkl')\n",
    "y_train_all = pd.read_pickle('response_doc2vec_train.pkl')\n",
    "y_test_all = pd.read_pickle('response_doc2vec_test.pkl')\n",
    "y_train_all = y_train_all.iloc[:,3:10]\n",
    "y_test_all = y_test_all.iloc[:,3:10]\n",
    "y_train_one = y_train_all.iloc[:,0]\n",
    "y_test_one = y_test_all.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_MLkNN50 = y_train_all\n",
    "y_test_MLkNN = y_test_all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.asarray(X_train)\n",
    "#y_train_MLkNN50 = y_train_MLkNN50.rename_axis('ID').values #turning df into numpy array\n",
    "y_train_MLkNN50 = np.asarray(y_train_MLkNN50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n",
      "[CV] k=10, s=0.5 .....................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ......................... k=10, s=0.5, score=0.406, total= 2.6min\n",
      "[CV] k=10, s=0.5 .....................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  2.6min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ......................... k=10, s=0.5, score=0.393, total= 2.7min\n",
      "[CV] k=10, s=0.5 .....................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  5.3min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ......................... k=10, s=0.5, score=0.396, total= 2.8min\n",
      "[CV] k=10, s=0.7 .....................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:  8.0min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ......................... k=10, s=0.7, score=0.406, total= 2.6min\n",
      "[CV] k=10, s=0.7 .....................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed: 10.6min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ......................... k=10, s=0.7, score=0.393, total= 2.7min\n",
      "[CV] k=10, s=0.7 .....................................................\n",
      "[CV] ......................... k=10, s=0.7, score=0.396, total= 2.9min\n",
      "[CV] k=10, s=1.0 .....................................................\n",
      "[CV] ......................... k=10, s=1.0, score=0.406, total= 2.7min\n",
      "[CV] k=10, s=1.0 .....................................................\n",
      "[CV] ......................... k=10, s=1.0, score=0.393, total= 2.5min\n",
      "[CV] k=10, s=1.0 .....................................................\n",
      "[CV] ......................... k=10, s=1.0, score=0.396, total= 2.5min\n",
      "[CV] k=20, s=0.5 .....................................................\n",
      "[CV] ......................... k=20, s=0.5, score=0.385, total= 2.8min\n",
      "[CV] k=20, s=0.5 .....................................................\n",
      "[CV] ......................... k=20, s=0.5, score=0.385, total= 2.8min\n",
      "[CV] k=20, s=0.5 .....................................................\n",
      "[CV] ......................... k=20, s=0.5, score=0.383, total= 2.8min\n",
      "[CV] k=20, s=0.7 .....................................................\n",
      "[CV] ......................... k=20, s=0.7, score=0.385, total= 2.6min\n",
      "[CV] k=20, s=0.7 .....................................................\n",
      "[CV] ......................... k=20, s=0.7, score=0.385, total= 2.6min\n",
      "[CV] k=20, s=0.7 .....................................................\n",
      "[CV] ......................... k=20, s=0.7, score=0.383, total= 2.6min\n",
      "[CV] k=20, s=1.0 .....................................................\n",
      "[CV] ......................... k=20, s=1.0, score=0.385, total= 2.7min\n",
      "[CV] k=20, s=1.0 .....................................................\n",
      "[CV] ......................... k=20, s=1.0, score=0.385, total= 2.6min\n",
      "[CV] k=20, s=1.0 .....................................................\n",
      "[CV] ......................... k=20, s=1.0, score=0.383, total= 2.7min\n",
      "[CV] k=30, s=0.5 .....................................................\n",
      "[CV] ......................... k=30, s=0.5, score=0.394, total= 2.9min\n",
      "[CV] k=30, s=0.5 .....................................................\n",
      "[CV] ......................... k=30, s=0.5, score=0.380, total= 2.8min\n",
      "[CV] k=30, s=0.5 .....................................................\n",
      "[CV] ......................... k=30, s=0.5, score=0.378, total= 2.8min\n",
      "[CV] k=30, s=0.7 .....................................................\n",
      "[CV] ......................... k=30, s=0.7, score=0.394, total= 2.7min\n",
      "[CV] k=30, s=0.7 .....................................................\n",
      "[CV] ......................... k=30, s=0.7, score=0.380, total= 2.7min\n",
      "[CV] k=30, s=0.7 .....................................................\n",
      "[CV] ......................... k=30, s=0.7, score=0.378, total= 2.8min\n",
      "[CV] k=30, s=1.0 .....................................................\n",
      "[CV] ......................... k=30, s=1.0, score=0.394, total= 2.7min\n",
      "[CV] k=30, s=1.0 .....................................................\n",
      "[CV] ......................... k=30, s=1.0, score=0.380, total= 2.7min\n",
      "[CV] k=30, s=1.0 .....................................................\n",
      "[CV] ......................... k=30, s=1.0, score=0.378, total= 2.7min\n",
      "[CV] k=40, s=0.5 .....................................................\n",
      "[CV] ......................... k=40, s=0.5, score=0.392, total= 2.8min\n",
      "[CV] k=40, s=0.5 .....................................................\n",
      "[CV] ......................... k=40, s=0.5, score=0.376, total= 2.7min\n",
      "[CV] k=40, s=0.5 .....................................................\n",
      "[CV] ......................... k=40, s=0.5, score=0.390, total= 2.7min\n",
      "[CV] k=40, s=0.7 .....................................................\n",
      "[CV] ......................... k=40, s=0.7, score=0.392, total= 2.8min\n",
      "[CV] k=40, s=0.7 .....................................................\n",
      "[CV] ......................... k=40, s=0.7, score=0.376, total= 3.1min\n",
      "[CV] k=40, s=0.7 .....................................................\n",
      "[CV] ......................... k=40, s=0.7, score=0.390, total= 2.8min\n",
      "[CV] k=40, s=1.0 .....................................................\n",
      "[CV] ......................... k=40, s=1.0, score=0.392, total= 2.7min\n",
      "[CV] k=40, s=1.0 .....................................................\n",
      "[CV] ......................... k=40, s=1.0, score=0.376, total= 2.7min\n",
      "[CV] k=40, s=1.0 .....................................................\n",
      "[CV] ......................... k=40, s=1.0, score=0.390, total= 2.7min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  36 out of  36 | elapsed: 98.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'k': 10, 's': 0.5} 0.39829904622016976\n"
     ]
    }
   ],
   "source": [
    "from skmultilearn.adapt import MLkNN\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameters = {'k': range(10,50,10), 's': [0.5, 0.7, 1.0]}\n",
    "\n",
    "clf = GridSearchCV(MLkNN(), parameters, scoring='f1_macro', verbose = 5)\n",
    "clf.fit(X_train, y_train_MLkNN50)\n",
    "\n",
    "print (clf.best_params_, clf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# took 98.1 min\n",
    "# 36 fits\n",
    "# best from 10 to 40 was k = 10, s = 0.5\n",
    "# 'k': 10, 's': 0.5} 0.39829904622016976"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # MLkNN for s - smoothing parameter\n",
    " Resource:\n",
    " https://cs.nju.edu.cn/zhouzh/zhouzh.files/publication/pr07.pdf\n",
    " \n",
    " Furthermore, the input argument s is a smoothing parameter controlling the strength of uniform prior (In this paper, s is set to be 1 which yields the Laplace smoothing).\n",
    " \n",
    " Laplace Smoothing. In statistics, Laplace Smoothing is a technique to smooth categorical data. Laplace Smoothing is introduced to solve the problem of zero probability. from 0 to 1\n",
    " \n",
    " \n",
    " \n",
    " # for K\n",
    " http://lup.lub.lu.se/luur/download?func=downloadFile&recordOId=8933695&fileOId=8933698\n",
    " \n",
    " The multi-label methods used in this work were explained in section 2.3 and\n",
    "were implemented by making use of code created by Min-Ling Zhang [27].\n",
    "For the MLKNN method the number of neighbours used was chosen to be\n",
    "30 as was done for the single-label KNN method. The other parameters\n",
    "for the MLKNN method were chosen to be the default values presented in\n",
    "[30]. For the ML-RBF method the default values were used as parameters\n",
    "since changes to these values did not produce any noticeable increase in\n",
    "classification accuracy. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:1978: FutureWarning:\n",
      "\n",
      "The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "[CV] k=3, s=0.5 ......................................................\n",
      "[CV] .......................... k=3, s=0.5, score=0.414, total= 2.6min\n",
      "[CV] k=3, s=0.5 ......................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  2.6min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .......................... k=3, s=0.5, score=0.414, total= 2.5min\n",
      "[CV] k=3, s=0.5 ......................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  5.2min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .......................... k=3, s=0.5, score=0.411, total= 2.5min\n",
      "[CV] k=3, s=1.0 ......................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:  7.7min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .......................... k=3, s=1.0, score=0.414, total= 2.4min\n",
      "[CV] k=3, s=1.0 ......................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed: 10.1min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .......................... k=3, s=1.0, score=0.414, total= 2.4min\n",
      "[CV] k=3, s=1.0 ......................................................\n",
      "[CV] .......................... k=3, s=1.0, score=0.411, total= 2.4min\n",
      "[CV] k=4, s=0.5 ......................................................\n",
      "[CV] .......................... k=4, s=0.5, score=0.429, total= 2.4min\n",
      "[CV] k=4, s=0.5 ......................................................\n",
      "[CV] .......................... k=4, s=0.5, score=0.404, total= 2.5min\n",
      "[CV] k=4, s=0.5 ......................................................\n",
      "[CV] .......................... k=4, s=0.5, score=0.452, total= 2.5min\n",
      "[CV] k=4, s=1.0 ......................................................\n",
      "[CV] .......................... k=4, s=1.0, score=0.429, total= 2.4min\n",
      "[CV] k=4, s=1.0 ......................................................\n",
      "[CV] .......................... k=4, s=1.0, score=0.404, total= 2.5min\n",
      "[CV] k=4, s=1.0 ......................................................\n",
      "[CV] .......................... k=4, s=1.0, score=0.452, total= 2.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  12 out of  12 | elapsed: 29.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'k': 4, 's': 0.5} 0.4280822442015816\n"
     ]
    }
   ],
   "source": [
    "from skmultilearn.adapt import MLkNN\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameters = {'k': range(3,5), 's': [0.5, 1.0]}\n",
    "\n",
    "clf = GridSearchCV(MLkNN(), parameters, scoring='f1_macro', verbose = 5)\n",
    "clf.fit(X_train, y_train_MLkNN50)\n",
    "\n",
    "print (clf.best_params_, clf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimal parmaeters {'k': 4, 's': 0.5} 0.4280822442015816\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skmultilearn.adapt import MLkNN\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameters = {'k': range(3,5), 's': [0.5, 1.0]}\n",
    "\n",
    "clf = GridSearchCV(MLkNN(), parameters, scoring='f1_macro', verbose = 5)\n",
    "clf.fit(X_train, y_train_MLkNN50)\n",
    "\n",
    "print (clf.best_params_, clf.best_score_)\n",
    "\n",
    "\n",
    "\n",
    "predictions_MNB_BR = clf_MNB_BR.predict(X_test_MNB_BR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_mlknn = y_train_all\n",
    "y_test_mlknn = y_test_all\n",
    "X_train_mlknn = np.asarray(X_train)\n",
    "y_train_mlknn = np.asarray(y_train_mlknn)\n",
    "X_test_mlknn = np.asarray(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlknn = MLkNN(k=4, s=0.5)\n",
    "\n",
    "begin = dt.datetime.now()\n",
    "\n",
    "mlknn.fit(X_train_mlknn, y_train_mlknn)\n",
    "y_pred_mlknn = mlknn.predict(X_test_mlknn)\n",
    "y_pred_train_mlknn = mlknn.predict(X_train_mlknn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run time: 0:09:49.191633; training accuracy: 0.3832216734314636; training precision: 0.7519839057126109; training F1: 0.7232767293857527. testing accuracy: 0.12948655256723715; testing precision: 0.4907048179906204; testing F1: 0.48961869820420817.\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"Run time: {};\".format(dt.datetime.now() - begin),\n",
    "    \"training accuracy: {};\".format(accuracy_score(y_train_mlknn, y_pred_train_mlknn)),\n",
    "    \"training precision: {};\".format(precision_score(y_train_mlknn, y_pred_train_mlknn, average = 'weighted')),\n",
    "    \"training F1: {}.\".format(f1_score(y_train_mlknn, y_pred_train_mlknn, average = 'weighted')),\n",
    "    \"testing accuracy: {};\".format(accuracy_score(y_test_mlknn, y_pred_mlknn)),\n",
    "    \"testing precision: {};\".format(precision_score(y_test_mlknn, y_pred_mlknn, average = 'weighted')),\n",
    "    \"testing F1: {}.\".format(f1_score(y_test_mlknn, y_pred_mlknn, average = 'weighted'))\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import zero_one_loss\n",
    "from sklearn.metrics import hamming_loss\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def eval_multi_metrics(ytrue, ypred):\n",
    "    print (\"The Accuracy Score is:\",accuracy_score(ytrue, ypred))\n",
    "    print (\"The Zero One Loss is:\",zero_one_loss(ytrue, ypred))\n",
    "    print (\"The Hamming Loss is:\",hamming_loss(ytrue, ypred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "     \"\"\"\n",
    "     INPUT:\n",
    "    :param ytrue: ground truth\n",
    "    :param ypred: predictions\n",
    "\n",
    "     \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Accuracy Score is: 0.12948655256723715\n",
      "The Zero One Loss is: 0.8705134474327628\n",
      "The Hamming Loss is: 0.27334963325183376\n"
     ]
    }
   ],
   "source": [
    "eval_multi_metrics(y_test_mlknn, y_pred_mlknn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_bi_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multinomial Naive Bayes - Binary Relevance\n",
    "\n",
    "* USED MIN MAX SCALER TO REMOVE NEGATIVE VALUES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_MNB_BR = y_train_all\n",
    "y_test_MNB_BR = y_test_all\n",
    "X_train_MNB_BR = X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "scaler.fit(X_train_MNB_BR)\n",
    "\n",
    "X_train_MNB_BR = scaler.transform(X_train_MNB_BR)\n",
    "\n",
    "X_test_MNB_BR = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1852322738386308"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using binary relevance\n",
    "from skmultilearn.problem_transform import BinaryRelevance\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# initialize binary relevance multi-label classifier\n",
    "# with a gaussian naive bayes base classifier\n",
    "clf_MNB_BR = BinaryRelevance(MultinomialNB())\n",
    "\n",
    "# train\n",
    "clf_MNB_BR.fit(X_train_MNB_BR, y_train_MNB_BR)\n",
    "\n",
    "# predict\n",
    "predictions_MNB_BR = clf_MNB_BR.predict(X_test_MNB_BR)\n",
    "\n",
    "# accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test_MNB_BR,predictions_MNB_BR) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_test_MNB_BR.value_counts())\n",
    "\n",
    "# calculate null accuracy (for multi-class classification problems)\n",
    "# .head(1) assesses the value 1208\n",
    "null_accuracy = y_test_MNB_BR.value_counts().head(1) / len(y_test_MNB_BR)\n",
    "print('Null accuracy:', null_accuracy)\n",
    "\n",
    "# Manual calculation of null accuracy by always predicting the majority class\n",
    "print('Manual null accuracy:',(5617 / (5617 + 4609)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate AUC\n",
    "metrics.roc_auc_score(y_test_MNB_BR, y_pred_prob)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multinomial Naive Bayes - Classifier Chains\n",
    "\n",
    " * used MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOT RUN YET\n",
    "\n",
    "y_train_MNB_cc = y_train_all\n",
    "y_test_MNB_cc = y_test_all\n",
    "X_train_MNB_cc = X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "scaler.fit(X_train_MNB_cc)\n",
    "\n",
    "X_train_MNB_cc = scaler.transform(X_train_MNB_cc)\n",
    "X_test_MNB_cc = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1852322738386308"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using classifier chains\n",
    "from skmultilearn.problem_transform import ClassifierChain\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# initialize classifier chains multi-label classifier\n",
    "# with a gaussian naive bayes base classifier\n",
    "clf_MNB_cc = LabelPowerset(MultinomialNB())\n",
    "\n",
    "# train\n",
    "clf_MNB_cc.fit(X_train_MNB_cc, y_train_MNB_cc)\n",
    "\n",
    "# predict\n",
    "predictions_MNB_cc = clf_MNB_cc.predict(X_test_MNB_cc)\n",
    "\n",
    "accuracy_score(y_test_MNB_cc,predictions_MNB_cc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multinomial Naive Bayes - Label Powerset\n",
    "\n",
    " * Used MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_train_MNB_LP = y_train_all\n",
    "y_test_MNB_LP = y_test_all\n",
    "X_train_MNB_LP = X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "scaler.fit(X_train_MNB_LP)\n",
    "\n",
    "X_train_MNB_LP = scaler.transform(X_train_MNB_LP)\n",
    "X_test_MNB_LP = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1852322738386308"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using Label Powerset\n",
    "from skmultilearn.problem_transform import LabelPowerset\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# NOT RUN YET\n",
    "\n",
    "# initialize Label Powerset multi-label classifier\n",
    "# with a gaussian naive bayes base classifier\n",
    "clf_MNB_LP = LabelPowerset(MultinomialNB())\n",
    "\n",
    "# train\n",
    "clf_MNB_LP.fit(X_train_MNB_LP, y_train_MNB_LP)\n",
    "\n",
    "# predict\n",
    "predictions_MNB_LP = clf_MNB_LP.predict(X_test_MNB_LP)\n",
    "\n",
    "accuracy_score(y_test_MNB_LP,predictions_MNB_LP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bernoulli Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ngnb = BernoulliNB()\\ngnb.fit(X_train,y_train_all)\\ngnb_y_pred = gnb.predict(X_test)\\naccuracyBNB = gnb.score(X_test,y_test_all)\\nprint(\"Accuracy for bernoulli naive bayes:\", accuracyBNB)\\n# print the confusion matrix\\nmetrics.confusion_matrix(y_test_all, gnb_y_pred)'"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MAYBE NOT TO RUN \n",
    "'''\n",
    "gnb = BernoulliNB()\n",
    "gnb.fit(X_train,y_train_all)\n",
    "gnb_y_pred = gnb.predict(X_test)\n",
    "accuracyBNB = gnb.score(X_test,y_test_all)\n",
    "print(\"Accuracy for bernoulli naive bayes:\", accuracyBNB)\n",
    "# print the confusion matrix\n",
    "metrics.confusion_matrix(y_test_all, gnb_y_pred)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# notes for me\n",
    "\n",
    "\n",
    "\n",
    "#### The below applies to multi-classification problems which is NOT the same as multi-label.\n",
    "\n",
    "#### OneVsRest - problem transformation method\n",
    "\n",
    "#### treats the problem like multiple sets of binary classification problems\n",
    "\n",
    "* Traditional two-class and multi-class problems can both be cast into multi-label ones by restricting each instance to have only one label. On the other hand, the generality of multi-label problems inevitably makes it more difficult to learn. An intuitive approach to solving multi-label problem is to decompose it into multiple independent binary classification problems (one per category).\n",
    "\n",
    "* In an “one-to-rest” strategy, one could build multiple independent classifiers and, for an unseen instance, choose the class for which the confidence is maximized.\n",
    "\n",
    "* The main assumption here is that the labels are mutually exclusive. You do not consider any underlying correlation between the classes in this method.\n",
    "\n",
    "* For instance, it is more like asking simple questions, say, “is the comment toxic or not”, “is the comment threatening or not?”, etc. Also there might be an extensive case of overfitting here, since most of the comments are unlabeled, i,e., most of the comments are clean comments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# more notes for me\n",
    "Choosing ML algoriths\n",
    "We chose machine learning multicategory classification algorithms from the following seven algorithmic families: support vector machines, ridge classification, regularized logistic regression, Bayesian logistic regression, random forests, k-nearest neighbors. \n",
    "\n",
    "\n",
    "Since all the classification tasks were multicategory (that is, with three or more classes) and most of the employed classifiers (except for random forests, k-nearest neighbors) are designed for binary classification problems (that is, with two classes), we can adopt a one-versus-rest approach for the latter methods.\n",
    "\n",
    "We can train separate binary classifiers for each class against the rest and then classify new samples by taking a vote of the binary classifiers and choosing the class with the ‘strongest’ vote. The one-versus-rest approach for classification is known to be among the best performing methods for multicategory classification for other types of data.\n",
    "\n",
    "Random forests, k-nearest neighbors can solve multicategory problems natively and can be applied directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
