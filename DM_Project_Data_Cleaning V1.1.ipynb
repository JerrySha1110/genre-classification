{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langdetect\n",
      "  Downloading https://files.pythonhosted.org/packages/59/59/4bc44158a767a6d66de18c4136c8aa90491d56cc951c10b74dd1e13213c9/langdetect-1.0.7.zip (998kB)\n",
      "Requirement already satisfied: six in c:\\users\\peter\\anaconda3\\lib\\site-packages (from langdetect) (1.12.0)\n",
      "Building wheels for collected packages: langdetect\n",
      "  Building wheel for langdetect (setup.py): started\n",
      "  Building wheel for langdetect (setup.py): finished with status 'done'\n",
      "  Stored in directory: C:\\Users\\peter\\AppData\\Local\\pip\\Cache\\wheels\\ec\\0c\\a9\\1647275e7ef5014e7b83ff30105180e332867d65e7617ddafe\n",
      "Successfully built langdetect\n",
      "Installing collected packages: langdetect\n",
      "Successfully installed langdetect-1.0.7\n"
     ]
    }
   ],
   "source": [
    "#!pip install textblob\n",
    "#!pip install langdetect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "import re\n",
    "import random\n",
    "import nltk\n",
    "from scipy import sparse\n",
    "from scipy.sparse import csr_matrix, vstack\n",
    "from textblob import TextBlob\n",
    "from langdetect import detect_langs\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.stem.porter import *\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from gensim.models import Word2Vec\n",
    "import multiprocessing\n",
    "import gensim\n",
    "from gensim.utils import simple_preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "songdata = pd.read_csv('E:\\\\Roy Master File\\\\Winter2020\\\\Data Mining\\\\final\\\\Final Notebooks\\\\songdata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>song</th>\n",
       "      <th>link</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>Ahe's My Kind Of Girl</td>\n",
       "      <td>/a/abba/ahes+my+kind+of+girl_20598417.html</td>\n",
       "      <td>Look at her face, it's a wonderful face  \\nAnd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>Andante, Andante</td>\n",
       "      <td>/a/abba/andante+andante_20002708.html</td>\n",
       "      <td>Take it easy with me, please  \\nTouch me gentl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>As Good As New</td>\n",
       "      <td>/a/abba/as+good+as+new_20003033.html</td>\n",
       "      <td>I'll never know why I had to go  \\nWhy I had t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>Bang</td>\n",
       "      <td>/a/abba/bang_20598415.html</td>\n",
       "      <td>Making somebody happy is a question of give an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>Bang-A-Boomerang</td>\n",
       "      <td>/a/abba/bang+a+boomerang_20002668.html</td>\n",
       "      <td>Making somebody happy is a question of give an...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  artist                   song                                        link  \\\n",
       "0   ABBA  Ahe's My Kind Of Girl  /a/abba/ahes+my+kind+of+girl_20598417.html   \n",
       "1   ABBA       Andante, Andante       /a/abba/andante+andante_20002708.html   \n",
       "2   ABBA         As Good As New        /a/abba/as+good+as+new_20003033.html   \n",
       "3   ABBA                   Bang                  /a/abba/bang_20598415.html   \n",
       "4   ABBA       Bang-A-Boomerang      /a/abba/bang+a+boomerang_20002668.html   \n",
       "\n",
       "                                                text  \n",
       "0  Look at her face, it's a wonderful face  \\nAnd...  \n",
       "1  Take it easy with me, please  \\nTouch me gentl...  \n",
       "2  I'll never know why I had to go  \\nWhy I had t...  \n",
       "3  Making somebody happy is a question of give an...  \n",
       "4  Making somebody happy is a question of give an...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "songdata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"E:\\\\Roy Master File\\\\Winter2020\\\\Data Mining\\\\final\\\\Final Notebooks\\\\genres.pkl\")\n",
    "df = pd.merge(songdata, df, on=['artist','artist'])\n",
    "df = df[df.iloc[:,5:].any(axis = 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>song</th>\n",
       "      <th>link</th>\n",
       "      <th>text</th>\n",
       "      <th>genres</th>\n",
       "      <th>rock</th>\n",
       "      <th>singer-songwriter</th>\n",
       "      <th>pop</th>\n",
       "      <th>metal</th>\n",
       "      <th>folk</th>\n",
       "      <th>country</th>\n",
       "      <th>hip hop / rap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>Ahe's My Kind Of Girl</td>\n",
       "      <td>/a/abba/ahes+my+kind+of+girl_20598417.html</td>\n",
       "      <td>Look at her face, it's a wonderful face  \\nAnd...</td>\n",
       "      <td>[europop, swedish pop]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>Andante, Andante</td>\n",
       "      <td>/a/abba/andante+andante_20002708.html</td>\n",
       "      <td>Take it easy with me, please  \\nTouch me gentl...</td>\n",
       "      <td>[europop, swedish pop]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>As Good As New</td>\n",
       "      <td>/a/abba/as+good+as+new_20003033.html</td>\n",
       "      <td>I'll never know why I had to go  \\nWhy I had t...</td>\n",
       "      <td>[europop, swedish pop]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>Bang</td>\n",
       "      <td>/a/abba/bang_20598415.html</td>\n",
       "      <td>Making somebody happy is a question of give an...</td>\n",
       "      <td>[europop, swedish pop]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>Bang-A-Boomerang</td>\n",
       "      <td>/a/abba/bang+a+boomerang_20002668.html</td>\n",
       "      <td>Making somebody happy is a question of give an...</td>\n",
       "      <td>[europop, swedish pop]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  artist                   song                                        link  \\\n",
       "0   ABBA  Ahe's My Kind Of Girl  /a/abba/ahes+my+kind+of+girl_20598417.html   \n",
       "1   ABBA       Andante, Andante       /a/abba/andante+andante_20002708.html   \n",
       "2   ABBA         As Good As New        /a/abba/as+good+as+new_20003033.html   \n",
       "3   ABBA                   Bang                  /a/abba/bang_20598415.html   \n",
       "4   ABBA       Bang-A-Boomerang      /a/abba/bang+a+boomerang_20002668.html   \n",
       "\n",
       "                                                text                  genres  \\\n",
       "0  Look at her face, it's a wonderful face  \\nAnd...  [europop, swedish pop]   \n",
       "1  Take it easy with me, please  \\nTouch me gentl...  [europop, swedish pop]   \n",
       "2  I'll never know why I had to go  \\nWhy I had t...  [europop, swedish pop]   \n",
       "3  Making somebody happy is a question of give an...  [europop, swedish pop]   \n",
       "4  Making somebody happy is a question of give an...  [europop, swedish pop]   \n",
       "\n",
       "   rock  singer-songwriter  pop  metal  folk  country  hip hop / rap  \n",
       "0     0                  0    1      0     0        0              0  \n",
       "1     0                  0    1      0     0        0              0  \n",
       "2     0                  0    1      0     0        0              0  \n",
       "3     0                  0    1      0     0        0              0  \n",
       "4     0                  0    1      0     0        0              0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 51489 entries, 0 to 57595\n",
      "Data columns (total 12 columns):\n",
      "artist               51489 non-null object\n",
      "song                 51489 non-null object\n",
      "link                 51489 non-null object\n",
      "text                 51489 non-null object\n",
      "genres               51489 non-null object\n",
      "rock                 51489 non-null int32\n",
      "singer-songwriter    51489 non-null int32\n",
      "pop                  51489 non-null int32\n",
      "metal                51489 non-null int32\n",
      "folk                 51489 non-null int32\n",
      "country              51489 non-null int32\n",
      "hip hop / rap        51489 non-null int32\n",
      "dtypes: int32(7), object(5)\n",
      "memory usage: 3.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a multilabel classification problem according to https://scikit-learn.org/stable/modules/multiclass.html\n",
    "\n",
    "Multilabel- \n",
    "\n",
    "\"A multiclass multioutput target where each output is binary. This may be represented as a 2d (dense) array or sparse matrix of integers, such that each column is a separate binary target, where positive labels are indicated with 1 and negative labels are usually -1 or 0. Sparse multilabel targets are not supported everywhere that dense multilabel targets are supported.\"\n",
    "\n",
    "\"Valid representation of multilabel y is either dense (or sparse) binary matrix of shape (n_samples, n_classes). Each column represents a class. The 1’s in each row denote the positive classes a sample has been labelled with.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#here is y in array form if you want it.\n",
    "#this would have happened in a train_test_split anyway\n",
    "y = np.array(df.iloc[:,5:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some text is in round brackets while some is in square brackets. I wanted to examine what that text looked like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54962\n"
     ]
    }
   ],
   "source": [
    "#examining text in round brackets\n",
    "round_brackets = sum(list(df['text'].map(lambda s: re.findall(r'\\((.*?)\\)',s))), [])\n",
    "#Number of round brackets:\n",
    "print((len(round_brackets)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I knew',\n",
       " 'tell it',\n",
       " 'gunshots',\n",
       " \"feel like I'm back\",\n",
       " 'Judy',\n",
       " 'we were in the park',\n",
       " \"You don't own\",\n",
       " 'repeat to fade',\n",
       " \"it's alright\",\n",
       " 'Originally recorded by Diamond Head',\n",
       " 'or should I have my green eyes?',\n",
       " 'Dark night',\n",
       " 'vocals',\n",
       " 'I got 1,000 hugs and kisses 4 U when U come back home, baby',\n",
       " \"But that's alright\"]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Viewing some text in round brackets\n",
    "#These just look like normal lyrics\n",
    "random.seed(0)\n",
    "random.choices(round_brackets, k=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26001\n"
     ]
    }
   ],
   "source": [
    "#examining text in square brackets\n",
    "square_brackets = sum(list(df['text'].map(lambda s: re.findall(r'\\[(.*?)\\]',s))), [])\n",
    "#how many instances of square brackets?\n",
    "print((len(square_brackets)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#re.sub(pattern, repl, string, count=0, flags=0)\n",
    "# remove round brackets but not text within\n",
    "df['text'] = df['text'].map(lambda s: re.sub(r'\\(|\\)', '', s))\n",
    "\n",
    "# remove square brackest and text within\n",
    "df['text'] = df['text'].map(lambda s: re.sub(r'\\[(.*?)\\] ', '', s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove line breaks\n",
    "df['text'] = df['text'].map(lambda s: re.sub(r' \\n|\\n', '', s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing Non-English Songs\n",
    "\n",
    "Note: This takes a while to run. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of songs in english: 51129\n",
      "Number of songs that are not english: 360\n"
     ]
    }
   ],
   "source": [
    "#This find the probability that the word is english\n",
    "def get_eng_prob(text):\n",
    "    detections = detect_langs(text)\n",
    "    for detection in detections:\n",
    "        if detection.lang == 'en':\n",
    "            return detection.prob\n",
    "    return 0\n",
    "\n",
    "#finding the probability that the text is english\n",
    "df['en_prob'] = df['text'].map(get_eng_prob)\n",
    "\n",
    "print('Number of songs in english: {}'.format(sum(df['en_prob'] >= 0.5)))\n",
    "print('Number of songs that are not english: {}'.format(sum(df['en_prob'] < 0.5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#only selecting songs that have a probability of 0.5 or higher of being in english\n",
    "df = df.loc[df['en_prob'] >= 0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>song</th>\n",
       "      <th>link</th>\n",
       "      <th>text</th>\n",
       "      <th>genres</th>\n",
       "      <th>rock</th>\n",
       "      <th>singer-songwriter</th>\n",
       "      <th>pop</th>\n",
       "      <th>metal</th>\n",
       "      <th>folk</th>\n",
       "      <th>country</th>\n",
       "      <th>hip hop / rap</th>\n",
       "      <th>en_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>Ahe's My Kind Of Girl</td>\n",
       "      <td>/a/abba/ahes+my+kind+of+girl_20598417.html</td>\n",
       "      <td>Look at her face, it's a wonderful face And it...</td>\n",
       "      <td>[europop, swedish pop]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>Andante, Andante</td>\n",
       "      <td>/a/abba/andante+andante_20002708.html</td>\n",
       "      <td>Take it easy with me, please Touch me gently l...</td>\n",
       "      <td>[europop, swedish pop]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>As Good As New</td>\n",
       "      <td>/a/abba/as+good+as+new_20003033.html</td>\n",
       "      <td>I'll never know why I had to go Why I had to p...</td>\n",
       "      <td>[europop, swedish pop]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>Bang</td>\n",
       "      <td>/a/abba/bang_20598415.html</td>\n",
       "      <td>Making somebody happy is a question of give an...</td>\n",
       "      <td>[europop, swedish pop]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>Bang-A-Boomerang</td>\n",
       "      <td>/a/abba/bang+a+boomerang_20002668.html</td>\n",
       "      <td>Making somebody happy is a question of give an...</td>\n",
       "      <td>[europop, swedish pop]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999997</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  artist                   song                                        link  \\\n",
       "0   ABBA  Ahe's My Kind Of Girl  /a/abba/ahes+my+kind+of+girl_20598417.html   \n",
       "1   ABBA       Andante, Andante       /a/abba/andante+andante_20002708.html   \n",
       "2   ABBA         As Good As New        /a/abba/as+good+as+new_20003033.html   \n",
       "3   ABBA                   Bang                  /a/abba/bang_20598415.html   \n",
       "4   ABBA       Bang-A-Boomerang      /a/abba/bang+a+boomerang_20002668.html   \n",
       "\n",
       "                                                text                  genres  \\\n",
       "0  Look at her face, it's a wonderful face And it...  [europop, swedish pop]   \n",
       "1  Take it easy with me, please Touch me gently l...  [europop, swedish pop]   \n",
       "2  I'll never know why I had to go Why I had to p...  [europop, swedish pop]   \n",
       "3  Making somebody happy is a question of give an...  [europop, swedish pop]   \n",
       "4  Making somebody happy is a question of give an...  [europop, swedish pop]   \n",
       "\n",
       "   rock  singer-songwriter  pop  metal  folk  country  hip hop / rap   en_prob  \n",
       "0     0                  0    1      0     0        0              0  0.999996  \n",
       "1     0                  0    1      0     0        0              0  0.999996  \n",
       "2     0                  0    1      0     0        0              0  0.999998  \n",
       "3     0                  0    1      0     0        0              0  0.999996  \n",
       "4     0                  0    1      0     0        0              0  0.999997  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of songs in english: 51129\n",
      "Number of songs that are not english: 0\n"
     ]
    }
   ],
   "source": [
    "#Repeating above code to make sure that the non-english songs were dropped\n",
    "print('Number of songs in english: {}'.format(sum(df['en_prob'] >= 0.5)))\n",
    "print('Number of songs that are not english: {}'.format(sum(df['en_prob'] < 0.5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['en_prob'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization\n",
    "\n",
    "Using nltk.tokenize to seperate the text into a list of words. All punctuation is removed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#w+ for whitespace\n",
    "#tokenizer = nltk.tokenize.RegexpTokenizer(r'\\w+')\n",
    "\n",
    "#creating a new column called tokens\n",
    "#df['tokens'] = df['text'].map(tokenizer.tokenize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We originally cleaned the data using the tokenization text above. After later running the word2vec, we didn't like that the words were not lowercased, and thought they could be cleaned up better. We are proceeding with the code below instead. According to documentation, this uses tokenize() internally.\n",
    "\n",
    "https://radimrehurek.com/gensim/utils.html"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "stemmer = PorterStemmer()\n",
    "def lemmatize_stemming(text):\n",
    "    \"\"\"\n",
    "       Also Borrowed from our preprocessing module.\n",
    "    \"\"\"\n",
    "    return stemmer.stem(WordNetLemmatizer().lemmatize(text, pos='v'))\n",
    "\n",
    "def preprocess(text):\n",
    "    \"\"\"\n",
    "        Edited function from our Preprocessing pipeline\n",
    "        Doesn't remove stopwords as it turns out some stopwords like 'NO' is actually very importan\n",
    "    \n",
    "    \"\"\"\n",
    "    result = []\n",
    "    #stopwords = list(gensim.parsing.preprocessing.STOPWORDS)\n",
    "    #stopwords.pop(stopwords.index('no'))\n",
    "    for token in gensim.utils.simple_preprocess(text):\n",
    "        #if token not in set(stopwords):\n",
    "        result.append(lemmatize_stemming(token))\n",
    "    return ' '.join(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Roy's\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\wordnet.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text_preprocessed'] = df['text'].map(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>song</th>\n",
       "      <th>link</th>\n",
       "      <th>text</th>\n",
       "      <th>genres</th>\n",
       "      <th>rock</th>\n",
       "      <th>singer-songwriter</th>\n",
       "      <th>pop</th>\n",
       "      <th>metal</th>\n",
       "      <th>folk</th>\n",
       "      <th>country</th>\n",
       "      <th>hip hop / rap</th>\n",
       "      <th>text_preprocessed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>Ahe's My Kind Of Girl</td>\n",
       "      <td>/a/abba/ahes+my+kind+of+girl_20598417.html</td>\n",
       "      <td>Look at her face, it's a wonderful face And it...</td>\n",
       "      <td>[europop, swedish pop]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>look at her face it wonder face and it mean so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>Andante, Andante</td>\n",
       "      <td>/a/abba/andante+andante_20002708.html</td>\n",
       "      <td>Take it easy with me, please Touch me gently l...</td>\n",
       "      <td>[europop, swedish pop]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>take it easi with me pleas touch me gentli lik...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>As Good As New</td>\n",
       "      <td>/a/abba/as+good+as+new_20003033.html</td>\n",
       "      <td>I'll never know why I had to go Why I had to p...</td>\n",
       "      <td>[europop, swedish pop]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ll never know whi have to go whi have to put u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>Bang</td>\n",
       "      <td>/a/abba/bang_20598415.html</td>\n",
       "      <td>Making somebody happy is a question of give an...</td>\n",
       "      <td>[europop, swedish pop]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>make somebodi happi be question of give and ta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>Bang-A-Boomerang</td>\n",
       "      <td>/a/abba/bang+a+boomerang_20002668.html</td>\n",
       "      <td>Making somebody happy is a question of give an...</td>\n",
       "      <td>[europop, swedish pop]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>make somebodi happi be question of give and ta...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  artist                   song                                        link  \\\n",
       "0   ABBA  Ahe's My Kind Of Girl  /a/abba/ahes+my+kind+of+girl_20598417.html   \n",
       "1   ABBA       Andante, Andante       /a/abba/andante+andante_20002708.html   \n",
       "2   ABBA         As Good As New        /a/abba/as+good+as+new_20003033.html   \n",
       "3   ABBA                   Bang                  /a/abba/bang_20598415.html   \n",
       "4   ABBA       Bang-A-Boomerang      /a/abba/bang+a+boomerang_20002668.html   \n",
       "\n",
       "                                                text                  genres  \\\n",
       "0  Look at her face, it's a wonderful face And it...  [europop, swedish pop]   \n",
       "1  Take it easy with me, please Touch me gently l...  [europop, swedish pop]   \n",
       "2  I'll never know why I had to go Why I had to p...  [europop, swedish pop]   \n",
       "3  Making somebody happy is a question of give an...  [europop, swedish pop]   \n",
       "4  Making somebody happy is a question of give an...  [europop, swedish pop]   \n",
       "\n",
       "   rock  singer-songwriter  pop  metal  folk  country  hip hop / rap  \\\n",
       "0     0                  0    1      0     0        0              0   \n",
       "1     0                  0    1      0     0        0              0   \n",
       "2     0                  0    1      0     0        0              0   \n",
       "3     0                  0    1      0     0        0              0   \n",
       "4     0                  0    1      0     0        0              0   \n",
       "\n",
       "                                   text_preprocessed  \n",
       "0  look at her face it wonder face and it mean so...  \n",
       "1  take it easi with me pleas touch me gentli lik...  \n",
       "2  ll never know whi have to go whi have to put u...  \n",
       "3  make somebodi happi be question of give and ta...  \n",
       "4  make somebodi happi be question of give and ta...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    look at her face it wonder face and it mean so...\n",
       "1    take it easi with me pleas touch me gentli lik...\n",
       "2    ll never know whi have to go whi have to put u...\n",
       "3    make somebodi happi be question of give and ta...\n",
       "4    make somebodi happi be question of give and ta...\n",
       "Name: text_preprocessed, dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking what the tokens column look like before removing stopwords\n",
    "df['text_preprocessed'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "#safety\n",
    "df2 = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#w+ for whitespace\n",
    "tokenizer = nltk.tokenize.RegexpTokenizer(r'\\w+')\n",
    "\n",
    "#creating a new column called tokens\n",
    "df['tokens'] = df['text_preprocessed'].map(tokenizer.tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>song</th>\n",
       "      <th>link</th>\n",
       "      <th>text</th>\n",
       "      <th>genres</th>\n",
       "      <th>rock</th>\n",
       "      <th>singer-songwriter</th>\n",
       "      <th>pop</th>\n",
       "      <th>metal</th>\n",
       "      <th>folk</th>\n",
       "      <th>country</th>\n",
       "      <th>hip hop / rap</th>\n",
       "      <th>text_preprocessed</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>Ahe's My Kind Of Girl</td>\n",
       "      <td>/a/abba/ahes+my+kind+of+girl_20598417.html</td>\n",
       "      <td>Look at her face, it's a wonderful face And it...</td>\n",
       "      <td>[europop, swedish pop]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>look at her face it wonder face and it mean so...</td>\n",
       "      <td>[look, at, her, face, it, wonder, face, and, i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>Andante, Andante</td>\n",
       "      <td>/a/abba/andante+andante_20002708.html</td>\n",
       "      <td>Take it easy with me, please Touch me gently l...</td>\n",
       "      <td>[europop, swedish pop]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>take it easi with me pleas touch me gentli lik...</td>\n",
       "      <td>[take, it, easi, with, me, pleas, touch, me, g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>As Good As New</td>\n",
       "      <td>/a/abba/as+good+as+new_20003033.html</td>\n",
       "      <td>I'll never know why I had to go Why I had to p...</td>\n",
       "      <td>[europop, swedish pop]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ll never know whi have to go whi have to put u...</td>\n",
       "      <td>[ll, never, know, whi, have, to, go, whi, have...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>Bang</td>\n",
       "      <td>/a/abba/bang_20598415.html</td>\n",
       "      <td>Making somebody happy is a question of give an...</td>\n",
       "      <td>[europop, swedish pop]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>make somebodi happi be question of give and ta...</td>\n",
       "      <td>[make, somebodi, happi, be, question, of, give...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>Bang-A-Boomerang</td>\n",
       "      <td>/a/abba/bang+a+boomerang_20002668.html</td>\n",
       "      <td>Making somebody happy is a question of give an...</td>\n",
       "      <td>[europop, swedish pop]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>make somebodi happi be question of give and ta...</td>\n",
       "      <td>[make, somebodi, happi, be, question, of, give...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57588</th>\n",
       "      <td>Van Der Graaf Generator</td>\n",
       "      <td>Man-Erg</td>\n",
       "      <td>/v/van+der+graaf+generator/man+erg_20260114.html</td>\n",
       "      <td>The killer lives inside me: I can feel him mov...</td>\n",
       "      <td>[art rock, canterbury scene, experimental, jaz...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>the killer live insid me can feel him move som...</td>\n",
       "      <td>[the, killer, live, insid, me, can, feel, him,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57589</th>\n",
       "      <td>Van Der Graaf Generator</td>\n",
       "      <td>Mirror Images</td>\n",
       "      <td>/v/van+der+graaf+generator/mirror+images_20263...</td>\n",
       "      <td>If I'm the mirror and you're the image Then wh...</td>\n",
       "      <td>[art rock, canterbury scene, experimental, jaz...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>if the mirror and you re the imag then what th...</td>\n",
       "      <td>[if, the, mirror, and, you, re, the, imag, the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57590</th>\n",
       "      <td>Van Der Graaf Generator</td>\n",
       "      <td>Sleepwalkers</td>\n",
       "      <td>/v/van+der+graaf+generator/sleepwalkers_202430...</td>\n",
       "      <td>At night, this mindless army, ranks unbroken b...</td>\n",
       "      <td>[art rock, canterbury scene, experimental, jaz...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>at night thi mindless armi rank unbroken by di...</td>\n",
       "      <td>[at, night, thi, mindless, armi, rank, unbroke...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57594</th>\n",
       "      <td>Zazie</td>\n",
       "      <td>Duo</td>\n",
       "      <td>/z/zazie/duo_20720322.html</td>\n",
       "      <td>Oui Je sens le vent Je sens la pluie Ressens l...</td>\n",
       "      <td>[chanson, french pop, french rock, nouvelle ch...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>oui je sen le vent je sen la pluie ressen la p...</td>\n",
       "      <td>[oui, je, sen, le, vent, je, sen, la, pluie, r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57595</th>\n",
       "      <td>Zazie</td>\n",
       "      <td>Snowball</td>\n",
       "      <td>/z/zazie/snowball_20287523.html</td>\n",
       "      <td>Red lights on the skyscrapers Snow white all o...</td>\n",
       "      <td>[chanson, french pop, french rock, nouvelle ch...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>red light on the skyscrap snow white all over ...</td>\n",
       "      <td>[red, light, on, the, skyscrap, snow, white, a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>51129 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        artist                   song  \\\n",
       "0                         ABBA  Ahe's My Kind Of Girl   \n",
       "1                         ABBA       Andante, Andante   \n",
       "2                         ABBA         As Good As New   \n",
       "3                         ABBA                   Bang   \n",
       "4                         ABBA       Bang-A-Boomerang   \n",
       "...                        ...                    ...   \n",
       "57588  Van Der Graaf Generator                Man-Erg   \n",
       "57589  Van Der Graaf Generator          Mirror Images   \n",
       "57590  Van Der Graaf Generator           Sleepwalkers   \n",
       "57594                    Zazie                    Duo   \n",
       "57595                    Zazie               Snowball   \n",
       "\n",
       "                                                    link  \\\n",
       "0             /a/abba/ahes+my+kind+of+girl_20598417.html   \n",
       "1                  /a/abba/andante+andante_20002708.html   \n",
       "2                   /a/abba/as+good+as+new_20003033.html   \n",
       "3                             /a/abba/bang_20598415.html   \n",
       "4                 /a/abba/bang+a+boomerang_20002668.html   \n",
       "...                                                  ...   \n",
       "57588   /v/van+der+graaf+generator/man+erg_20260114.html   \n",
       "57589  /v/van+der+graaf+generator/mirror+images_20263...   \n",
       "57590  /v/van+der+graaf+generator/sleepwalkers_202430...   \n",
       "57594                         /z/zazie/duo_20720322.html   \n",
       "57595                    /z/zazie/snowball_20287523.html   \n",
       "\n",
       "                                                    text  \\\n",
       "0      Look at her face, it's a wonderful face And it...   \n",
       "1      Take it easy with me, please Touch me gently l...   \n",
       "2      I'll never know why I had to go Why I had to p...   \n",
       "3      Making somebody happy is a question of give an...   \n",
       "4      Making somebody happy is a question of give an...   \n",
       "...                                                  ...   \n",
       "57588  The killer lives inside me: I can feel him mov...   \n",
       "57589  If I'm the mirror and you're the image Then wh...   \n",
       "57590  At night, this mindless army, ranks unbroken b...   \n",
       "57594  Oui Je sens le vent Je sens la pluie Ressens l...   \n",
       "57595  Red lights on the skyscrapers Snow white all o...   \n",
       "\n",
       "                                                  genres  rock  \\\n",
       "0                                 [europop, swedish pop]     0   \n",
       "1                                 [europop, swedish pop]     0   \n",
       "2                                 [europop, swedish pop]     0   \n",
       "3                                 [europop, swedish pop]     0   \n",
       "4                                 [europop, swedish pop]     0   \n",
       "...                                                  ...   ...   \n",
       "57588  [art rock, canterbury scene, experimental, jaz...     1   \n",
       "57589  [art rock, canterbury scene, experimental, jaz...     1   \n",
       "57590  [art rock, canterbury scene, experimental, jaz...     1   \n",
       "57594  [chanson, french pop, french rock, nouvelle ch...     1   \n",
       "57595  [chanson, french pop, french rock, nouvelle ch...     1   \n",
       "\n",
       "       singer-songwriter  pop  metal  folk  country  hip hop / rap  \\\n",
       "0                      0    1      0     0        0              0   \n",
       "1                      0    1      0     0        0              0   \n",
       "2                      0    1      0     0        0              0   \n",
       "3                      0    1      0     0        0              0   \n",
       "4                      0    1      0     0        0              0   \n",
       "...                  ...  ...    ...   ...      ...            ...   \n",
       "57588                  0    0      0     0        0              0   \n",
       "57589                  0    0      0     0        0              0   \n",
       "57590                  0    0      0     0        0              0   \n",
       "57594                  0    1      0     0        0              0   \n",
       "57595                  0    1      0     0        0              0   \n",
       "\n",
       "                                       text_preprocessed  \\\n",
       "0      look at her face it wonder face and it mean so...   \n",
       "1      take it easi with me pleas touch me gentli lik...   \n",
       "2      ll never know whi have to go whi have to put u...   \n",
       "3      make somebodi happi be question of give and ta...   \n",
       "4      make somebodi happi be question of give and ta...   \n",
       "...                                                  ...   \n",
       "57588  the killer live insid me can feel him move som...   \n",
       "57589  if the mirror and you re the imag then what th...   \n",
       "57590  at night thi mindless armi rank unbroken by di...   \n",
       "57594  oui je sen le vent je sen la pluie ressen la p...   \n",
       "57595  red light on the skyscrap snow white all over ...   \n",
       "\n",
       "                                                  tokens  \n",
       "0      [look, at, her, face, it, wonder, face, and, i...  \n",
       "1      [take, it, easi, with, me, pleas, touch, me, g...  \n",
       "2      [ll, never, know, whi, have, to, go, whi, have...  \n",
       "3      [make, somebodi, happi, be, question, of, give...  \n",
       "4      [make, somebodi, happi, be, question, of, give...  \n",
       "...                                                  ...  \n",
       "57588  [the, killer, live, insid, me, can, feel, him,...  \n",
       "57589  [if, the, mirror, and, you, re, the, imag, the...  \n",
       "57590  [at, night, thi, mindless, armi, rank, unbroke...  \n",
       "57594  [oui, je, sen, le, vent, je, sen, la, pluie, r...  \n",
       "57595  [red, light, on, the, skyscrap, snow, white, a...  \n",
       "\n",
       "[51129 rows x 14 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing stop words\n",
    "Reference for more info: https://www.geeksforgeeks.org/removing-stop-words-nltk-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Roy's\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#setting stop words\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing stop words\n",
    "df['tokens'] = df['tokens'].apply(lambda x: [item for item in x if item not in stop_words])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>song</th>\n",
       "      <th>link</th>\n",
       "      <th>text</th>\n",
       "      <th>genres</th>\n",
       "      <th>rock</th>\n",
       "      <th>singer-songwriter</th>\n",
       "      <th>pop</th>\n",
       "      <th>metal</th>\n",
       "      <th>folk</th>\n",
       "      <th>country</th>\n",
       "      <th>hip hop / rap</th>\n",
       "      <th>text_preprocessed</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>Ahe's My Kind Of Girl</td>\n",
       "      <td>/a/abba/ahes+my+kind+of+girl_20598417.html</td>\n",
       "      <td>Look at her face, it's a wonderful face And it...</td>\n",
       "      <td>[europop, swedish pop]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>look at her face it wonder face and it mean so...</td>\n",
       "      <td>[look, face, wonder, face, mean, someth, speci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>Andante, Andante</td>\n",
       "      <td>/a/abba/andante+andante_20002708.html</td>\n",
       "      <td>Take it easy with me, please Touch me gently l...</td>\n",
       "      <td>[europop, swedish pop]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>take it easi with me pleas touch me gentli lik...</td>\n",
       "      <td>[take, easi, pleas, touch, gentli, like, summe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>As Good As New</td>\n",
       "      <td>/a/abba/as+good+as+new_20003033.html</td>\n",
       "      <td>I'll never know why I had to go Why I had to p...</td>\n",
       "      <td>[europop, swedish pop]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ll never know whi have to go whi have to put u...</td>\n",
       "      <td>[never, know, whi, go, whi, put, lousi, rotten...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>Bang</td>\n",
       "      <td>/a/abba/bang_20598415.html</td>\n",
       "      <td>Making somebody happy is a question of give an...</td>\n",
       "      <td>[europop, swedish pop]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>make somebodi happi be question of give and ta...</td>\n",
       "      <td>[make, somebodi, happi, question, give, take, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>Bang-A-Boomerang</td>\n",
       "      <td>/a/abba/bang+a+boomerang_20002668.html</td>\n",
       "      <td>Making somebody happy is a question of give an...</td>\n",
       "      <td>[europop, swedish pop]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>make somebodi happi be question of give and ta...</td>\n",
       "      <td>[make, somebodi, happi, question, give, take, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  artist                   song                                        link  \\\n",
       "0   ABBA  Ahe's My Kind Of Girl  /a/abba/ahes+my+kind+of+girl_20598417.html   \n",
       "1   ABBA       Andante, Andante       /a/abba/andante+andante_20002708.html   \n",
       "2   ABBA         As Good As New        /a/abba/as+good+as+new_20003033.html   \n",
       "3   ABBA                   Bang                  /a/abba/bang_20598415.html   \n",
       "4   ABBA       Bang-A-Boomerang      /a/abba/bang+a+boomerang_20002668.html   \n",
       "\n",
       "                                                text                  genres  \\\n",
       "0  Look at her face, it's a wonderful face And it...  [europop, swedish pop]   \n",
       "1  Take it easy with me, please Touch me gently l...  [europop, swedish pop]   \n",
       "2  I'll never know why I had to go Why I had to p...  [europop, swedish pop]   \n",
       "3  Making somebody happy is a question of give an...  [europop, swedish pop]   \n",
       "4  Making somebody happy is a question of give an...  [europop, swedish pop]   \n",
       "\n",
       "   rock  singer-songwriter  pop  metal  folk  country  hip hop / rap  \\\n",
       "0     0                  0    1      0     0        0              0   \n",
       "1     0                  0    1      0     0        0              0   \n",
       "2     0                  0    1      0     0        0              0   \n",
       "3     0                  0    1      0     0        0              0   \n",
       "4     0                  0    1      0     0        0              0   \n",
       "\n",
       "                                   text_preprocessed  \\\n",
       "0  look at her face it wonder face and it mean so...   \n",
       "1  take it easi with me pleas touch me gentli lik...   \n",
       "2  ll never know whi have to go whi have to put u...   \n",
       "3  make somebodi happi be question of give and ta...   \n",
       "4  make somebodi happi be question of give and ta...   \n",
       "\n",
       "                                              tokens  \n",
       "0  [look, face, wonder, face, mean, someth, speci...  \n",
       "1  [take, easi, pleas, touch, gentli, like, summe...  \n",
       "2  [never, know, whi, go, whi, put, lousi, rotten...  \n",
       "3  [make, somebodi, happi, question, give, take, ...  \n",
       "4  [make, somebodi, happi, question, give, take, ...  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stemming the data - stemming done above in pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import these modules \n",
    "from nltk.stem import WordNetLemmatizer \n",
    "  \n",
    "lemmatizer = WordNetLemmatizer() \n",
    " \n",
    "# create dictionary to map tokens their lem\n",
    "token_to_lem = {}\n",
    "# initialise word count\n",
    "token_count = 0\n",
    "\n",
    "\n",
    "# iterate through all songs\n",
    "for lst in df['tokens']:\n",
    "    # iterate through all tokens of song\n",
    "    for token in lst:\n",
    "        token_count += 1\n",
    "        # check if token is in dictionary\n",
    "        if token not in token_to_lem:\n",
    "            # add token to dictionary\n",
    "            token_to_lem[token] = lemmatizer.lemmatize(token)\n",
    "    \n",
    "    \n",
    "#creating column stems            \n",
    "df['stems'] = df['tokens'].map(lambda lst: [token_to_lem[token] for token in lst])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We give the option to either lemmatization or stemming. We ran both and compared our outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#intialize stemmer\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "# create dictionary to map tokens their stem\n",
    "token_to_stem = {}\n",
    "# initialise word count\n",
    "token_count = 0\n",
    "\n",
    "\n",
    "# iterate through all songs\n",
    "for lst in df['tokens']:\n",
    "    # iterate through all tokens of song\n",
    "    for token in lst:\n",
    "        token_count += 1\n",
    "        # check if token is in dictionary\n",
    "        if token not in token_to_stem:\n",
    "            # add token to dictionary\n",
    "            token_to_stem[token] = stemmer.stem(token)\n",
    "\n",
    "#creating column stems            \n",
    "df['stems'] = df['tokens'].map(lambda lst: [token_to_stem[token] for token in lst])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>song</th>\n",
       "      <th>link</th>\n",
       "      <th>text</th>\n",
       "      <th>genres</th>\n",
       "      <th>rock</th>\n",
       "      <th>singer-songwriter</th>\n",
       "      <th>pop</th>\n",
       "      <th>metal</th>\n",
       "      <th>folk</th>\n",
       "      <th>country</th>\n",
       "      <th>hip hop / rap</th>\n",
       "      <th>text_preprocessed</th>\n",
       "      <th>tokens</th>\n",
       "      <th>stems</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>Ahe's My Kind Of Girl</td>\n",
       "      <td>/a/abba/ahes+my+kind+of+girl_20598417.html</td>\n",
       "      <td>Look at her face, it's a wonderful face And it...</td>\n",
       "      <td>[europop, swedish pop]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>look at her face it wonder face and it mean so...</td>\n",
       "      <td>[look, face, wonder, face, mean, someth, speci...</td>\n",
       "      <td>[look, face, wonder, face, mean, someth, speci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>Andante, Andante</td>\n",
       "      <td>/a/abba/andante+andante_20002708.html</td>\n",
       "      <td>Take it easy with me, please Touch me gently l...</td>\n",
       "      <td>[europop, swedish pop]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>take it easi with me pleas touch me gentli lik...</td>\n",
       "      <td>[take, easi, pleas, touch, gentli, like, summe...</td>\n",
       "      <td>[take, easi, plea, touch, gentli, like, summer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>As Good As New</td>\n",
       "      <td>/a/abba/as+good+as+new_20003033.html</td>\n",
       "      <td>I'll never know why I had to go Why I had to p...</td>\n",
       "      <td>[europop, swedish pop]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ll never know whi have to go whi have to put u...</td>\n",
       "      <td>[never, know, whi, go, whi, put, lousi, rotten...</td>\n",
       "      <td>[never, know, whi, go, whi, put, lousi, rotten...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>Bang</td>\n",
       "      <td>/a/abba/bang_20598415.html</td>\n",
       "      <td>Making somebody happy is a question of give an...</td>\n",
       "      <td>[europop, swedish pop]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>make somebodi happi be question of give and ta...</td>\n",
       "      <td>[make, somebodi, happi, question, give, take, ...</td>\n",
       "      <td>[make, somebodi, happi, question, give, take, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>Bang-A-Boomerang</td>\n",
       "      <td>/a/abba/bang+a+boomerang_20002668.html</td>\n",
       "      <td>Making somebody happy is a question of give an...</td>\n",
       "      <td>[europop, swedish pop]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>make somebodi happi be question of give and ta...</td>\n",
       "      <td>[make, somebodi, happi, question, give, take, ...</td>\n",
       "      <td>[make, somebodi, happi, question, give, take, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  artist                   song                                        link  \\\n",
       "0   ABBA  Ahe's My Kind Of Girl  /a/abba/ahes+my+kind+of+girl_20598417.html   \n",
       "1   ABBA       Andante, Andante       /a/abba/andante+andante_20002708.html   \n",
       "2   ABBA         As Good As New        /a/abba/as+good+as+new_20003033.html   \n",
       "3   ABBA                   Bang                  /a/abba/bang_20598415.html   \n",
       "4   ABBA       Bang-A-Boomerang      /a/abba/bang+a+boomerang_20002668.html   \n",
       "\n",
       "                                                text                  genres  \\\n",
       "0  Look at her face, it's a wonderful face And it...  [europop, swedish pop]   \n",
       "1  Take it easy with me, please Touch me gently l...  [europop, swedish pop]   \n",
       "2  I'll never know why I had to go Why I had to p...  [europop, swedish pop]   \n",
       "3  Making somebody happy is a question of give an...  [europop, swedish pop]   \n",
       "4  Making somebody happy is a question of give an...  [europop, swedish pop]   \n",
       "\n",
       "   rock  singer-songwriter  pop  metal  folk  country  hip hop / rap  \\\n",
       "0     0                  0    1      0     0        0              0   \n",
       "1     0                  0    1      0     0        0              0   \n",
       "2     0                  0    1      0     0        0              0   \n",
       "3     0                  0    1      0     0        0              0   \n",
       "4     0                  0    1      0     0        0              0   \n",
       "\n",
       "                                   text_preprocessed  \\\n",
       "0  look at her face it wonder face and it mean so...   \n",
       "1  take it easi with me pleas touch me gentli lik...   \n",
       "2  ll never know whi have to go whi have to put u...   \n",
       "3  make somebodi happi be question of give and ta...   \n",
       "4  make somebodi happi be question of give and ta...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [look, face, wonder, face, mean, someth, speci...   \n",
       "1  [take, easi, pleas, touch, gentli, like, summe...   \n",
       "2  [never, know, whi, go, whi, put, lousi, rotten...   \n",
       "3  [make, somebodi, happi, question, give, take, ...   \n",
       "4  [make, somebodi, happi, question, give, take, ...   \n",
       "\n",
       "                                               stems  \n",
       "0  [look, face, wonder, face, mean, someth, speci...  \n",
       "1  [take, easi, plea, touch, gentli, like, summer...  \n",
       "2  [never, know, whi, go, whi, put, lousi, rotten...  \n",
       "3  [make, somebodi, happi, question, give, take, ...  \n",
       "4  [make, somebodi, happi, question, give, take, ...  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 51129 entries, 0 to 57595\n",
      "Data columns (total 15 columns):\n",
      "artist               51129 non-null object\n",
      "song                 51129 non-null object\n",
      "link                 51129 non-null object\n",
      "text                 51129 non-null object\n",
      "genres               51129 non-null object\n",
      "rock                 51129 non-null int32\n",
      "singer-songwriter    51129 non-null int32\n",
      "pop                  51129 non-null int32\n",
      "metal                51129 non-null int32\n",
      "folk                 51129 non-null int32\n",
      "country              51129 non-null int32\n",
      "hip hop / rap        51129 non-null int32\n",
      "text_preprocessed    51129 non-null object\n",
      "tokens               51129 non-null object\n",
      "stems                51129 non-null object\n",
      "dtypes: int32(7), object(8)\n",
      "memory usage: 4.9+ MB\n"
     ]
    }
   ],
   "source": [
    "#checking out the data\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5623928\n"
     ]
    }
   ],
   "source": [
    "#number of tokens\n",
    "print(token_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51151"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#number of unique tokens\n",
    "len(token_to_stem.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50676"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#number of unique stems\n",
    "(len(set(token_to_stem.values())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#turning the stems back into untokenized structrure so that we can run count vector on it\n",
    "df['stem_str'] = df['tokens'].map(lambda lst: ' '.join(lst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>song</th>\n",
       "      <th>link</th>\n",
       "      <th>text</th>\n",
       "      <th>genres</th>\n",
       "      <th>rock</th>\n",
       "      <th>singer-songwriter</th>\n",
       "      <th>pop</th>\n",
       "      <th>metal</th>\n",
       "      <th>folk</th>\n",
       "      <th>country</th>\n",
       "      <th>hip hop / rap</th>\n",
       "      <th>text_preprocessed</th>\n",
       "      <th>tokens</th>\n",
       "      <th>stems</th>\n",
       "      <th>stem_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>Ahe's My Kind Of Girl</td>\n",
       "      <td>/a/abba/ahes+my+kind+of+girl_20598417.html</td>\n",
       "      <td>Look at her face, it's a wonderful face And it...</td>\n",
       "      <td>[europop, swedish pop]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>look at her face it wonder face and it mean so...</td>\n",
       "      <td>[look, face, wonder, face, mean, someth, speci...</td>\n",
       "      <td>[look, face, wonder, face, mean, someth, speci...</td>\n",
       "      <td>look face wonder face mean someth special look...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>Andante, Andante</td>\n",
       "      <td>/a/abba/andante+andante_20002708.html</td>\n",
       "      <td>Take it easy with me, please Touch me gently l...</td>\n",
       "      <td>[europop, swedish pop]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>take it easi with me pleas touch me gentli lik...</td>\n",
       "      <td>[take, easi, pleas, touch, gentli, like, summe...</td>\n",
       "      <td>[take, easi, plea, touch, gentli, like, summer...</td>\n",
       "      <td>take easi pleas touch gentli like summer even ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>As Good As New</td>\n",
       "      <td>/a/abba/as+good+as+new_20003033.html</td>\n",
       "      <td>I'll never know why I had to go Why I had to p...</td>\n",
       "      <td>[europop, swedish pop]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ll never know whi have to go whi have to put u...</td>\n",
       "      <td>[never, know, whi, go, whi, put, lousi, rotten...</td>\n",
       "      <td>[never, know, whi, go, whi, put, lousi, rotten...</td>\n",
       "      <td>never know whi go whi put lousi rotten show bo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>Bang</td>\n",
       "      <td>/a/abba/bang_20598415.html</td>\n",
       "      <td>Making somebody happy is a question of give an...</td>\n",
       "      <td>[europop, swedish pop]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>make somebodi happi be question of give and ta...</td>\n",
       "      <td>[make, somebodi, happi, question, give, take, ...</td>\n",
       "      <td>[make, somebodi, happi, question, give, take, ...</td>\n",
       "      <td>make somebodi happi question give take learn s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>Bang-A-Boomerang</td>\n",
       "      <td>/a/abba/bang+a+boomerang_20002668.html</td>\n",
       "      <td>Making somebody happy is a question of give an...</td>\n",
       "      <td>[europop, swedish pop]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>make somebodi happi be question of give and ta...</td>\n",
       "      <td>[make, somebodi, happi, question, give, take, ...</td>\n",
       "      <td>[make, somebodi, happi, question, give, take, ...</td>\n",
       "      <td>make somebodi happi question give take learn s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  artist                   song                                        link  \\\n",
       "0   ABBA  Ahe's My Kind Of Girl  /a/abba/ahes+my+kind+of+girl_20598417.html   \n",
       "1   ABBA       Andante, Andante       /a/abba/andante+andante_20002708.html   \n",
       "2   ABBA         As Good As New        /a/abba/as+good+as+new_20003033.html   \n",
       "3   ABBA                   Bang                  /a/abba/bang_20598415.html   \n",
       "4   ABBA       Bang-A-Boomerang      /a/abba/bang+a+boomerang_20002668.html   \n",
       "\n",
       "                                                text                  genres  \\\n",
       "0  Look at her face, it's a wonderful face And it...  [europop, swedish pop]   \n",
       "1  Take it easy with me, please Touch me gently l...  [europop, swedish pop]   \n",
       "2  I'll never know why I had to go Why I had to p...  [europop, swedish pop]   \n",
       "3  Making somebody happy is a question of give an...  [europop, swedish pop]   \n",
       "4  Making somebody happy is a question of give an...  [europop, swedish pop]   \n",
       "\n",
       "   rock  singer-songwriter  pop  metal  folk  country  hip hop / rap  \\\n",
       "0     0                  0    1      0     0        0              0   \n",
       "1     0                  0    1      0     0        0              0   \n",
       "2     0                  0    1      0     0        0              0   \n",
       "3     0                  0    1      0     0        0              0   \n",
       "4     0                  0    1      0     0        0              0   \n",
       "\n",
       "                                   text_preprocessed  \\\n",
       "0  look at her face it wonder face and it mean so...   \n",
       "1  take it easi with me pleas touch me gentli lik...   \n",
       "2  ll never know whi have to go whi have to put u...   \n",
       "3  make somebodi happi be question of give and ta...   \n",
       "4  make somebodi happi be question of give and ta...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [look, face, wonder, face, mean, someth, speci...   \n",
       "1  [take, easi, pleas, touch, gentli, like, summe...   \n",
       "2  [never, know, whi, go, whi, put, lousi, rotten...   \n",
       "3  [make, somebodi, happi, question, give, take, ...   \n",
       "4  [make, somebodi, happi, question, give, take, ...   \n",
       "\n",
       "                                               stems  \\\n",
       "0  [look, face, wonder, face, mean, someth, speci...   \n",
       "1  [take, easi, plea, touch, gentli, like, summer...   \n",
       "2  [never, know, whi, go, whi, put, lousi, rotten...   \n",
       "3  [make, somebodi, happi, question, give, take, ...   \n",
       "4  [make, somebodi, happi, question, give, take, ...   \n",
       "\n",
       "                                            stem_str  \n",
       "0  look face wonder face mean someth special look...  \n",
       "1  take easi pleas touch gentli like summer even ...  \n",
       "2  never know whi go whi put lousi rotten show bo...  \n",
       "3  make somebodi happi question give take learn s...  \n",
       "4  make somebodi happi question give take learn s...  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "from langdetect import detect\n",
    "# from wordcloud import WordCloud, STOPWORDS\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB, ComplementNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import svm\n",
    "import plotly.graph_objects as go\n",
    "# from better_profanity import profanity\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "import re\n",
    "from gensim import utils\n",
    "from gensim.models.doc2vec import LabeledSentence\n",
    "from gensim.models import Doc2Vec\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>song</th>\n",
       "      <th>link</th>\n",
       "      <th>text</th>\n",
       "      <th>genres</th>\n",
       "      <th>rock</th>\n",
       "      <th>singer-songwriter</th>\n",
       "      <th>pop</th>\n",
       "      <th>metal</th>\n",
       "      <th>folk</th>\n",
       "      <th>country</th>\n",
       "      <th>hip hop / rap</th>\n",
       "      <th>text_preprocessed</th>\n",
       "      <th>tokens</th>\n",
       "      <th>stems</th>\n",
       "      <th>stem_str</th>\n",
       "      <th>tokens2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>Ahe's My Kind Of Girl</td>\n",
       "      <td>/a/abba/ahes+my+kind+of+girl_20598417.html</td>\n",
       "      <td>Look at her face, it's a wonderful face And it...</td>\n",
       "      <td>[europop, swedish pop]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>look at her face it wonder face and it mean so...</td>\n",
       "      <td>[look, face, wonder, face, mean, someth, speci...</td>\n",
       "      <td>[look, face, wonder, face, mean, someth, speci...</td>\n",
       "      <td>look face wonder face mean someth special look...</td>\n",
       "      <td>'look', 'face', 'wonder', 'face', 'mean', 'som...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>Andante, Andante</td>\n",
       "      <td>/a/abba/andante+andante_20002708.html</td>\n",
       "      <td>Take it easy with me, please Touch me gently l...</td>\n",
       "      <td>[europop, swedish pop]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>take it easi with me pleas touch me gentli lik...</td>\n",
       "      <td>[take, easi, pleas, touch, gentli, like, summe...</td>\n",
       "      <td>[take, easi, plea, touch, gentli, like, summer...</td>\n",
       "      <td>take easi pleas touch gentli like summer even ...</td>\n",
       "      <td>'take', 'easi', 'pleas', 'touch', 'gentli', 'l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>As Good As New</td>\n",
       "      <td>/a/abba/as+good+as+new_20003033.html</td>\n",
       "      <td>I'll never know why I had to go Why I had to p...</td>\n",
       "      <td>[europop, swedish pop]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ll never know whi have to go whi have to put u...</td>\n",
       "      <td>[never, know, whi, go, whi, put, lousi, rotten...</td>\n",
       "      <td>[never, know, whi, go, whi, put, lousi, rotten...</td>\n",
       "      <td>never know whi go whi put lousi rotten show bo...</td>\n",
       "      <td>'never', 'know', 'whi', 'go', 'whi', 'put', 'l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>Bang</td>\n",
       "      <td>/a/abba/bang_20598415.html</td>\n",
       "      <td>Making somebody happy is a question of give an...</td>\n",
       "      <td>[europop, swedish pop]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>make somebodi happi be question of give and ta...</td>\n",
       "      <td>[make, somebodi, happi, question, give, take, ...</td>\n",
       "      <td>[make, somebodi, happi, question, give, take, ...</td>\n",
       "      <td>make somebodi happi question give take learn s...</td>\n",
       "      <td>'make', 'somebodi', 'happi', 'question', 'give...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>Bang-A-Boomerang</td>\n",
       "      <td>/a/abba/bang+a+boomerang_20002668.html</td>\n",
       "      <td>Making somebody happy is a question of give an...</td>\n",
       "      <td>[europop, swedish pop]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>make somebodi happi be question of give and ta...</td>\n",
       "      <td>[make, somebodi, happi, question, give, take, ...</td>\n",
       "      <td>[make, somebodi, happi, question, give, take, ...</td>\n",
       "      <td>make somebodi happi question give take learn s...</td>\n",
       "      <td>'make', 'somebodi', 'happi', 'question', 'give...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  artist                   song                                        link  \\\n",
       "0   ABBA  Ahe's My Kind Of Girl  /a/abba/ahes+my+kind+of+girl_20598417.html   \n",
       "1   ABBA       Andante, Andante       /a/abba/andante+andante_20002708.html   \n",
       "2   ABBA         As Good As New        /a/abba/as+good+as+new_20003033.html   \n",
       "3   ABBA                   Bang                  /a/abba/bang_20598415.html   \n",
       "4   ABBA       Bang-A-Boomerang      /a/abba/bang+a+boomerang_20002668.html   \n",
       "\n",
       "                                                text                  genres  \\\n",
       "0  Look at her face, it's a wonderful face And it...  [europop, swedish pop]   \n",
       "1  Take it easy with me, please Touch me gently l...  [europop, swedish pop]   \n",
       "2  I'll never know why I had to go Why I had to p...  [europop, swedish pop]   \n",
       "3  Making somebody happy is a question of give an...  [europop, swedish pop]   \n",
       "4  Making somebody happy is a question of give an...  [europop, swedish pop]   \n",
       "\n",
       "   rock  singer-songwriter  pop  metal  folk  country  hip hop / rap  \\\n",
       "0     0                  0    1      0     0        0              0   \n",
       "1     0                  0    1      0     0        0              0   \n",
       "2     0                  0    1      0     0        0              0   \n",
       "3     0                  0    1      0     0        0              0   \n",
       "4     0                  0    1      0     0        0              0   \n",
       "\n",
       "                                   text_preprocessed  \\\n",
       "0  look at her face it wonder face and it mean so...   \n",
       "1  take it easi with me pleas touch me gentli lik...   \n",
       "2  ll never know whi have to go whi have to put u...   \n",
       "3  make somebodi happi be question of give and ta...   \n",
       "4  make somebodi happi be question of give and ta...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [look, face, wonder, face, mean, someth, speci...   \n",
       "1  [take, easi, pleas, touch, gentli, like, summe...   \n",
       "2  [never, know, whi, go, whi, put, lousi, rotten...   \n",
       "3  [make, somebodi, happi, question, give, take, ...   \n",
       "4  [make, somebodi, happi, question, give, take, ...   \n",
       "\n",
       "                                               stems  \\\n",
       "0  [look, face, wonder, face, mean, someth, speci...   \n",
       "1  [take, easi, plea, touch, gentli, like, summer...   \n",
       "2  [never, know, whi, go, whi, put, lousi, rotten...   \n",
       "3  [make, somebodi, happi, question, give, take, ...   \n",
       "4  [make, somebodi, happi, question, give, take, ...   \n",
       "\n",
       "                                            stem_str  \\\n",
       "0  look face wonder face mean someth special look...   \n",
       "1  take easi pleas touch gentli like summer even ...   \n",
       "2  never know whi go whi put lousi rotten show bo...   \n",
       "3  make somebodi happi question give take learn s...   \n",
       "4  make somebodi happi question give take learn s...   \n",
       "\n",
       "                                             tokens2  \n",
       "0  'look', 'face', 'wonder', 'face', 'mean', 'som...  \n",
       "1  'take', 'easi', 'pleas', 'touch', 'gentli', 'l...  \n",
       "2  'never', 'know', 'whi', 'go', 'whi', 'put', 'l...  \n",
       "3  'make', 'somebodi', 'happi', 'question', 'give...  \n",
       "4  'make', 'somebodi', 'happi', 'question', 'give...  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tokens2']=df.tokens.apply(lambda x:str(x).strip('[]'))\n",
    "df.head()                  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer()\n",
    "\n",
    "stem_count_vector = cv.fit_transform(df['tokens2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df.tokens2, df['pop'], random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_cv = cv.fit_transform(X_train)\n",
    "X_test_cv = cv.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = MultinomialNB()\n",
    "nb.fit(X_train_cv, y_train)\n",
    "y_pred = nb.predict(X_test_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial Naive Bayes Accuracy: 0.6352968786669796\n"
     ]
    }
   ],
   "source": [
    "print('Multinomial Naive Bayes Accuracy:', accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.67      0.67      7097\n",
      "           1       0.59      0.59      0.59      5686\n",
      "\n",
      "    accuracy                           0.64     12783\n",
      "   macro avg       0.63      0.63      0.63     12783\n",
      "weighted avg       0.64      0.64      0.64     12783\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_pred,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Nearest Neighbors Accuracy for k= 17 : 0.7581944770398185\n",
      "K-Nearest Neighbors Accuracy for k= 19 : 0.7574121880622702\n",
      "K-Nearest Neighbors Accuracy for k= 20 : 0.7572557302667605\n"
     ]
    }
   ],
   "source": [
    "n = [17, 19, 20]\n",
    "\n",
    "for i in n:\n",
    "    knn = KNeighborsClassifier(n_neighbors = i)\n",
    "    knn.fit(X_train_cv, y_train)\n",
    "    y_pred_knn = knn.predict(X_test_cv)\n",
    "    print('K-Nearest Neighbors Accuracy for k=', i, ':', accuracy_score(y_test, y_pred_knn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38346,)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12783,)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tf-Idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer()\n",
    "X_train_cv = tfidf.fit_transform(X_train)\n",
    "X_test_cv = tfidf.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = MultinomialNB()\n",
    "nb.fit(X_train_cv, y_train)\n",
    "y_pred = nb.predict(X_test_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial Naive Bayes Accuracy: 0.8506610341860283\n"
     ]
    }
   ],
   "source": [
    "print('Multinomial Naive Bayes Accuracy:', accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Documentation: \n",
    "#https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfTransformer.html\n",
    "\n",
    "\n",
    "# initialise count vectorizer\n",
    "#Convert a collection of text documents to a matrix of token counts\n",
    "#This implementation produces a sparse representation of the counts using scipy.sparse.csr_matrix.\n",
    "#cv = CountVectorizer()\n",
    "\n",
    "# generate word counts\n",
    "#stem_count_vector = cv.fit_transform(df['stem_str'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<57175x50762 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 3334732 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#stem_count_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMB_DIM=300\n",
    "wv_model=Word2Vec(df[\"tokens\"],\n",
    "             size=EMB_DIM,\n",
    "             window=5,\n",
    "             min_count=5, \n",
    "             negative=15, \n",
    "             iter=10,\n",
    "             workers=multiprocessing.cpu_count(), \n",
    "             #defines the algorithm to use as the model. sg = skip-gram\n",
    "             #default is CBOW (Continuous bag of words)\n",
    "             sg = 1   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model from disk\n",
    "import pickle\n",
    "  \n",
    "# Save the trained model as a pickle string. \n",
    "pickle.dump(wv_model, open( \"songs_wv_model\", \"wb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectors=wv_model.wv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring different types of word similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('lorain', 0.6302295923233032),\n",
       " ('couldv', 0.6193580627441406),\n",
       " ('distantli', 0.6171380877494812),\n",
       " ('overreact', 0.6133875250816345),\n",
       " ('unconvent', 0.6129610538482666),\n",
       " ('unmerit', 0.6109627485275269),\n",
       " ('questionin', 0.6030411720275879),\n",
       " ('connot', 0.6023432016372681),\n",
       " ('loophol', 0.5982478260993958),\n",
       " ('emigr', 0.5925590991973877)]"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Exploring similar words\n",
    "#calling object similar_by_word\n",
    "word_vectors.similar_by_word('masterplan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vectors.most_similar(positive=['insertwordhere'],negative=['insertwordhere'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/breabeals/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DeprecationWarning:\n",
      "\n",
      "Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-2.24736318e-01,  1.97534621e-01, -4.29814868e-02,  5.71665466e-02,\n",
       "        5.65432794e-02,  1.85361847e-01, -6.85141310e-02,  8.89955685e-02,\n",
       "        1.21765053e-02,  2.06344709e-01, -1.14845835e-01, -1.25641763e-01,\n",
       "       -4.58884798e-03, -1.42729923e-03,  1.43025428e-01, -3.46773177e-01,\n",
       "        1.35805786e-01, -2.56192654e-01, -1.26809895e-01, -1.30737841e-01,\n",
       "        9.08707082e-02,  1.35844260e-01, -5.43559194e-02,  4.73242477e-02,\n",
       "        2.51561612e-01, -1.24103695e-01, -1.26703739e-01, -1.88817494e-02,\n",
       "        3.10138404e-01, -3.21486928e-02, -2.03293823e-02,  1.41334394e-02,\n",
       "       -1.42418832e-01, -6.57715797e-02, -1.12045988e-01,  1.60259008e-01,\n",
       "        1.85000822e-02,  1.49633542e-01, -8.46545473e-02, -9.50547680e-03,\n",
       "        5.91595583e-02, -1.16509996e-01,  4.31440026e-03,  3.29046361e-02,\n",
       "       -1.00284070e-01, -9.64479744e-02,  2.31143460e-01, -1.24456011e-01,\n",
       "        7.63623789e-02, -2.73124706e-02,  1.17235025e-02,  1.30105345e-03,\n",
       "        1.76290572e-01,  8.13145712e-02,  1.23784594e-01, -7.04271346e-02,\n",
       "        2.76564896e-01, -1.90152913e-01,  1.81408748e-01, -5.58746569e-02,\n",
       "        1.41019151e-01,  1.97566494e-01, -9.25799906e-02, -6.58866167e-02,\n",
       "       -1.69604504e-03,  3.28137465e-02, -3.38338539e-02, -2.56938040e-01,\n",
       "       -2.27604453e-02, -8.19249451e-02, -1.55938506e-01,  7.46764010e-03,\n",
       "        8.31638649e-02, -6.77590296e-02,  1.74724072e-01, -8.96205083e-02,\n",
       "       -1.28290430e-01, -2.56060734e-02, -8.19020867e-02, -1.87953681e-01,\n",
       "       -5.02296677e-03, -4.85777110e-02,  2.77173333e-02, -3.96085717e-02,\n",
       "        1.05949461e-01,  1.18659906e-01, -6.73286559e-04, -5.28888367e-02,\n",
       "        1.02058291e-01,  2.73336470e-01,  1.24527812e-01, -2.20185183e-02,\n",
       "        7.52717927e-02, -1.03098504e-01,  3.78298044e-01,  4.15418260e-02,\n",
       "       -6.71328380e-05, -1.48721009e-01, -2.36525796e-02, -1.27854183e-01,\n",
       "        2.24346384e-01,  1.48415625e-01,  1.44464150e-02,  1.36733741e-01,\n",
       "        2.09203184e-01,  2.38827839e-01, -1.13354199e-01, -7.02940673e-02,\n",
       "       -2.61263587e-02,  1.11787930e-01,  1.83259964e-01, -2.58659661e-01,\n",
       "       -9.67905223e-02,  1.55661162e-03,  3.66767198e-01, -2.07460493e-01,\n",
       "       -4.73914342e-03,  5.64589910e-02, -1.64229714e-03,  2.33604331e-02,\n",
       "        1.41441613e-01, -1.36170819e-01, -3.01247746e-01,  1.28419027e-01,\n",
       "        1.13408588e-01,  7.68720061e-02,  1.36228085e-01, -6.71759527e-03,\n",
       "       -2.82008708e-01,  1.76307023e-01,  2.79584020e-01,  1.28379717e-01,\n",
       "        7.11141378e-02, -3.27174515e-01,  1.05949387e-01, -1.11038178e-01,\n",
       "        6.86065406e-02, -5.20385876e-02,  2.18442217e-01, -1.28833130e-01,\n",
       "       -1.72818676e-01, -9.58222225e-02, -1.90981790e-01,  1.55857980e-01,\n",
       "       -1.43328123e-03,  1.21460222e-01,  1.81243539e-01, -1.06566556e-01,\n",
       "        1.91772968e-01, -1.60067737e-01, -1.17410114e-02, -3.31105180e-02,\n",
       "        1.91569597e-01, -7.35887289e-02,  3.57806869e-02, -2.80366153e-01,\n",
       "       -2.05583200e-02,  7.43774548e-02,  5.96090965e-02, -3.15311477e-02,\n",
       "        9.77665186e-03,  1.96030512e-01, -3.07896227e-01, -4.02413793e-02,\n",
       "       -1.81018084e-01,  4.79842983e-02,  2.18753800e-01, -1.97936982e-01,\n",
       "        2.32451886e-01,  7.38897501e-03,  3.53122167e-02,  4.48937453e-02,\n",
       "        2.80990750e-02,  7.95468688e-02, -1.08018562e-01, -4.66212779e-02,\n",
       "       -6.41077533e-02, -1.81254894e-01,  1.41713426e-01,  5.52472174e-02,\n",
       "        2.25181449e-02, -4.19314690e-02, -6.22941703e-02,  5.43500148e-02,\n",
       "       -1.85167149e-01,  4.09301892e-02, -6.55594990e-02, -1.78816155e-01,\n",
       "        2.04447851e-01,  1.20353803e-01, -1.92881361e-01,  1.45889878e-01,\n",
       "       -4.99732010e-02, -1.30403012e-01,  3.63916755e-02,  6.38696700e-02,\n",
       "        5.84882572e-02,  9.17248055e-02, -2.94666439e-02,  3.56133133e-01,\n",
       "       -1.36950940e-01, -5.00562228e-02,  1.68935299e-01,  1.26068398e-01,\n",
       "       -2.29425922e-01, -2.03327066e-03,  2.82410622e-01, -5.22621982e-02,\n",
       "       -1.47676438e-01,  1.48115203e-01, -1.41527846e-01, -6.77790791e-02,\n",
       "        8.55073333e-02,  1.58257589e-01, -9.27265361e-03, -2.52975941e-01,\n",
       "        3.28556485e-02,  7.09870160e-02, -2.14036003e-01,  3.06504369e-01,\n",
       "        2.72237267e-02,  9.82519761e-02, -1.35181457e-01,  9.90812555e-02,\n",
       "       -2.05888137e-01,  1.16345502e-01, -1.60293967e-01, -5.17657474e-02,\n",
       "        1.21842489e-01,  1.48655117e-01, -1.32162366e-02,  1.15314461e-01,\n",
       "       -5.20303287e-02,  1.20715551e-01, -3.73575948e-02, -2.29234938e-02,\n",
       "        1.51485596e-02,  3.36372703e-02, -6.21992946e-02,  7.74607509e-02,\n",
       "        3.11355246e-03, -1.75178364e-01, -1.00695185e-01, -3.81755829e-02,\n",
       "        1.47608042e-01,  6.76660985e-02, -5.32692485e-02, -2.74455249e-02,\n",
       "       -1.20726466e-01, -1.01514146e-01, -7.17153028e-02, -5.16707078e-02,\n",
       "        1.11457832e-01, -1.57852054e-01,  2.44259819e-01,  2.92766150e-02,\n",
       "       -3.68807912e-02,  3.09104789e-02,  1.86270744e-01,  9.65838879e-03,\n",
       "        1.05776684e-02, -7.25914352e-03, -8.87680426e-02,  9.95747186e-03,\n",
       "        2.29622461e-02,  7.43868202e-02, -4.20782762e-03, -1.20795280e-01,\n",
       "       -1.85329050e-01,  2.51578540e-01, -6.39409246e-03,  5.97047582e-02,\n",
       "        2.60821101e-03, -4.99352813e-03, -9.14622471e-02, -1.25717431e-01,\n",
       "       -2.39253312e-01, -3.67688984e-02, -5.08317761e-02, -2.04314776e-02,\n",
       "        3.58134173e-02,  7.94539750e-02,  1.00362569e-01,  7.61166587e-02,\n",
       "        1.32512301e-01,  5.64179756e-02,  1.69763207e-01,  1.30503133e-01,\n",
       "        1.61730014e-02,  1.25962824e-01, -2.15994954e-01, -9.75206196e-02,\n",
       "       -9.85578597e-02,  5.78645729e-02, -1.01189008e-02,  9.10660997e-02,\n",
       "        7.93493465e-02, -1.43866956e-01,  1.90720018e-02,  5.18888012e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#showing vector of individual words\n",
    "wv_model[\"love\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/breabeals/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: DeprecationWarning:\n",
      "\n",
      "Call to deprecated `similarity` (Method will be removed in 4.0.0, use self.wv.similarity() instead).\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.31420258"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv_model.similarity('love', 'hate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('Processed_Songs_Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
